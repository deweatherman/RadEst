{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import datetime \n",
    "import time\n",
    "from datetime import datetime \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pandas as pn\n",
    "import seaborn as sns\n",
    "#import sklearn\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error,r2_score\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor, HuberRegressor\n",
    "\n",
    "\n",
    "import pyOptimalEstimation as pyOE\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "from cmocean import cm as cmo\n",
    "\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nobackup/users/echeverr/anaconda3/envs/pyOpEst/lib/python3.7/typing.py:847: FutureWarning: xarray subclass customProfile should explicitly define __slots__\n",
      "  super().__init_subclass__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('lib')\n",
    "#import nonScatMWRadTran\n",
    "import supporting_routines\n",
    "import supporting_routines_m \n",
    "sys.path.append('/usr/people/echeverr/Documents/code/nwpsaf/rttov12/wrapper')\n",
    "import pyrttov\n",
    "import os\n",
    "\n",
    "rttov_installdir = '/usr/people/echeverr/Documents/code/nwpsaf/rttov12'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prior_all = supporting_routines_m.concatDiverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of levels for the profiles in the priors\n",
    "\n",
    "nlevels = len(prior_all['height'])\n",
    "nprofiles = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load successful >>>>> inst_id : 1, nchannels : 14.\n"
     ]
    }
   ],
   "source": [
    "# Channels corrispondence:\n",
    "\n",
    "# from: D. B. Kunkee et al, \"Design and Evaluation of the First \n",
    "# Special Sensor Microwave Imager/Sounder\", IEEE Trans. Geosc. Rem. Sens. \n",
    "# Vol. 46, NO. 4, April 2008.\n",
    "# Table 1\n",
    "# Ch. 1 - 50.3 GHz Hpol (check note on pol at source for this channel) \n",
    "# Ch. 12 - 19.35 GHz Hpol\n",
    "# Ch. 13 - 19.35 GHz Vpol\n",
    "# Ch. 14 - 22.235 GHz Vpol\n",
    "# Ch. 15 - 37 GHz Hpol\n",
    "# Ch. 16 - 37 GHz Vpol\n",
    "\n",
    "ssmiRttov = pyrttov.Rttov()\n",
    "\n",
    "# SSMIS:\n",
    "nchan_ssmi = 14\n",
    "chan_list_ssmi = (1,2,3,4,5,6,7,12,13,14,15,16,23,24) #(1,12,13,14,15,16) #  #\n",
    "ssmiRttov.FileCoef = '{}/{}'.format(rttov_installdir,\n",
    "                                    \"rtcoef_rttov12/rttov7pred54L/rtcoef_dmsp_18_ssmis.dat\")\n",
    "\n",
    "# WindSat:\n",
    "#nchan_ssmi = 16\n",
    "#chan_list_ssmi = (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16) #(1,2,3,4,7,8,11,12,13,14) #(1,12,13,14,15,16) #  #\n",
    "#ssmiRttov.FileCoef = '{}/{}'.format(rttov_installdir,\n",
    "#                                    \"rtcoef_rttov12/rttov7pred54L/rtcoef_coriolis_1_windsat.dat\")\n",
    "\n",
    "ssmiRttov.Options.AddInterp = True\n",
    "ssmiRttov.Options.CO2Data = False\n",
    "ssmiRttov.Options.VerboseWrapper = True\n",
    "ssmiRttov.Options.DoCheckinput = False\n",
    "ssmiRttov.Options.UseQ2m = True\n",
    "ssmiRttov.Options.ApplyRegLimits = True\n",
    "ssmiRttov.Options.Verbose = False\n",
    "ssmiRttov.Options.FastemVersion = 6 \n",
    "\n",
    "# Load the instruments: for HIRS and MHS do not supply a channel list and\n",
    "# so read all channels\n",
    "try:\n",
    "    ssmiRttov.loadInst(chan_list_ssmi)\n",
    "except pyrttov.RttovError as e:\n",
    "    sys.stderr.write(\"Error loading instrument(s): {!s}\".format(e))\n",
    "    sys.exit(1)\n",
    "\n",
    "# Load Atlases: (if any)    \n",
    "ssmiRttov.SurfEmisRefl = np.zeros((2,nprofiles,nchan_ssmi), dtype=np.float64)\n",
    "\n",
    "# Definition of the observation variables\n",
    "y_vars = np.array(chan_list_ssmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Values for the noise are obtained from HOAPS R matrix (Table 2, p20, HOAPS 4.0 ATBD)\n",
    "\n",
    "#y_noise = pn.Series(\n",
    "#    [\n",
    "#        2.44948974, 1.54919338, 1.341640787, 1.341640787, 1.949358869, 1.341640787\n",
    "#    ],\n",
    "#    index=y_vars\n",
    "#)\n",
    "\n",
    "#S_y = pn.DataFrame(\n",
    "#    np.diag(y_noise.values**2),\n",
    "#    index=y_vars,\n",
    "#    columns=y_vars,\n",
    "#)\n",
    "#\n",
    "\n",
    "# JUST FOR TESTING THE EFFECT ON SLOPE VIAS IN CROSS-VALIDATION (DON'T USE IN REAL APPLICATION)\n",
    "# Channels 1-7, 12-16, 23, 24 (MODIFIED values from Deblonde-English 2003) (sigma or std)\n",
    "#y_noise = pn.Series(\n",
    "#    [\n",
    "#        1.3, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 2.0, 1.07, 1.24, 2.5, 1.14, 0.46, 0.47\n",
    "#   ],\n",
    "#    index=y_vars\n",
    "#)\n",
    "# JUST FOR TESTING THE EFFECT ON SLOPE VIAS IN CROSS-VALIDATION (DON'T USE IN REAL APPLICATION)\n",
    "\n",
    "\n",
    "# FOR TEST USING NEDT VALUES FROM SSMIS ONLY (From Kunkee 2008)\n",
    "# Channels 1-7, 12-16, 23, 24 (values in K)\n",
    "#y_noise = pn.Series(\n",
    "#    [\n",
    "#        0.34, 0.32, 0.33, 0.33, 0.34, 0.41, 0.40, 0.33, 0.31, 0.43, 0.25, 0.20, 0.8, 0.9 \n",
    "#   ],\n",
    "#    index=y_vars\n",
    "#)\n",
    "# FOR TEST USING NEDT VALUES FROM SSMIS ONLY (From Kunkee 2008)\n",
    "\n",
    "\n",
    "# Channels 1-7, 12-16, 23, 24 (values from Deblonde-English 2003) (sigma or std)\n",
    "y_noise = pn.Series(\n",
    "    [\n",
    "        1.5, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 2.4, 1.27, 1.44, 3.0, 1.34, 0.46, 0.47\n",
    "   ],\n",
    "    index=y_vars\n",
    ")\n",
    "\n",
    "# Channels 1-7, 13,14,16, 23, 24 (values from Deblonde-English 2003) (sigma or std)\n",
    "#y_noise = pn.Series(\n",
    "#    [\n",
    "#        1.5, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 1.27, 1.44, 1.34, 0.46, 0.47\n",
    "#    ],\n",
    "#    index=y_vars\n",
    "#)\n",
    "\n",
    "# Channels 1,12-16 (values from Deblonde-English 2003) (sigma or std)\n",
    "#y_noise = pn.Series(\n",
    "#    [\n",
    "#        1.5, 2.4, 1.27, 1.44, 3.0, 1.34\n",
    "#    ],\n",
    "#    index=y_vars\n",
    "#)\n",
    "\n",
    "# Channels 2-7, 23, 24 (values from Deblonde-English 2003) (sigma or std)\n",
    "#y_noise = pn.Series(\n",
    "#    [\n",
    "#        0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.46, 0.47\n",
    "#    ],\n",
    "#    index=y_vars\n",
    "#)\n",
    "\n",
    "\n",
    "# Channels 1-16 WindSat (from Table 2 in M. Bettenhausen et al, \n",
    "# \"A Nonlinear Optimization Algorithm for WindSat Wind Vector Retrievals\", \n",
    "# IEEE Trans. Geo. Rem. Sen., Vol 44, No. 3, March 2006):\n",
    "\n",
    "# Take \"Polarimetric\" channels away:\n",
    "#y_noise = pn.Series(\n",
    "#    [\n",
    "#        0.60, 0.78, 0.69, 0.99, 1.02, 2.02, 1.38,\n",
    "#        2.51, 1.76, 3.65\n",
    "#    ],\n",
    "#    index=y_vars\n",
    "#)\n",
    "\n",
    "#y_noise = pn.Series(\n",
    "#    [\n",
    "#        0.60, 0.78, 0.69, 0.99, 0.26, 0.09, 1.02, 2.02, 0.28, 0.12, 1.38,\n",
    "#        2.51, 1.76, 3.65, 0.25, 0.09\n",
    "#    ],\n",
    "#    index=y_vars\n",
    "#)\n",
    "\n",
    "# Variance values > std**2\n",
    "S_y = pn.DataFrame(\n",
    "    np.diag(y_noise.values**2),\n",
    "    index=y_vars,\n",
    "    columns=y_vars,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the indices of the \"local prior\":\n",
    "# we will call local prior to the prior built\n",
    "# using a geographical area \"nearby\" the observation\n",
    "# location (i.e. a bounding box around the observation location). \n",
    "# All the atmospheric states within such a box \n",
    "# Define our a-priori knowledge (in the spatial domain)\n",
    "\n",
    "lat_min = -90.0\n",
    "lat_max = -40.0\n",
    "long_min = -180.0\n",
    "long_max = 180.0\n",
    "\n",
    "\n",
    "lat_long_mask = np.array([(prior_all['lat'].values[:]>lat_min)&(prior_all['lat'].values[:]<lat_max)&\n",
    "                 ((prior_all['long'].values[:]>long_min)&(prior_all['long'].values[:]<long_max))])\n",
    "lat_long_mask=lat_long_mask.reshape(-1)\n",
    "#lat_long_mask = ~lat_long_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(chan_list_ssmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3650\n"
     ]
    }
   ],
   "source": [
    "# Creating a time index for the local prior:\n",
    "times1 = prior_all['Time'].values[lat_long_mask]\n",
    "\n",
    "time_index = np.zeros(len(times1),dtype='datetime64[s]')\n",
    "for i in range(len(times1)):\n",
    "    time_index[i] = supporting_routines_m.timestamp2datetime(times1[i])\n",
    "print(len(times1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lat, long vectors for auxiliary plots e.g. cartopy\n",
    "\n",
    "lat = prior_all['lat'].values[lat_long_mask]\n",
    "long = prior_all['long'].values[lat_long_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a \"local\" prior: Subset of \"prior_all\" \n",
    "# that contains only the selected lat,long area.\n",
    "\n",
    "prior_local = supporting_routines_m.maskPrior(prior_all, time_index, lat_long_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the humidity profiles to a logarithmic scale\n",
    "# in order to improve their normality (see probability plots)\n",
    "\n",
    "# IMPORTANT NOTE:\n",
    "# RTTOV ACCEPTS ONLY kg / kg (LINEAR SCALE)\n",
    "# THERE IS A LOG2LIN CONVERSION IN THE DEFINITION\n",
    "# OF THE FORWARD OPERATOR; BUT INSIDE THE OPTIMAL\n",
    "# ESTIMATION, THE HUMIDITY IS IN LOG SCALE\n",
    "\n",
    "prior_local['Humidity'] = np.log10(prior_local['Humidity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def nearest(items, pivot):\n",
    "#    return min(items, key=lambda x: abs(x - pivot))\n",
    "len(x_truth.values[:])\n",
    "#Pressure, press2m, temp2m, hum2m, tskin, salinity\n",
    "y_obs\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.01 s, iteration 1, degrees of freedom: 1.73 of 3, converged (x-space):  0.182\n",
      "4.48 s, iteration 2, degrees of freedom: 1.72 of 3, done.  0.004\n",
      "index:\n",
      "0\n",
      "2.91 s, iteration 1, degrees of freedom: 1.81 of 3, converged (x-space):  0.026\n",
      "4.34 s, iteration 2, degrees of freedom: 1.82 of 3, done.  0.006\n",
      "index:\n",
      "1\n",
      "2.87 s, iteration 1, degrees of freedom: 1.77 of 3, not converged (x-space):  0.410\n",
      "4.30 s, iteration 2, degrees of freedom: 1.75 of 3, converged (x-space):  0.001\n",
      "5.72 s, iteration 3, degrees of freedom: 1.75 of 3, done.  0.000\n",
      "index:\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6f392985801b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m#oe_1.doRetrieval()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0moe_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoRetrieval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moe_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverged\u001b[0m \u001b[0;34m:\u001b[0m  \u001b[0;31m# oe_1 if windDisambiguation used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nobackup/users/echeverr/anaconda3/envs/pyOpEst/lib/python3.7/site-packages/pyOptimalEstimation-1.1-py3.7.egg/pyOptimalEstimation/pyOEcore.py\u001b[0m in \u001b[0;36mdoRetrieval\u001b[0;34m(self, maxIter, x_0, maxTime)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             self.K_i[i], self.K_b_i[i] = self.getJacobian(\n\u001b[0;32m--> 378\u001b[0;31m                 pd.concat((self.x_i[i], self.b_p)), self.y_i[i])\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nobackup/users/echeverr/anaconda3/envs/pyOpEst/lib/python3.7/site-packages/pyOptimalEstimation-1.1-py3.7.egg/pyOptimalEstimation/pyOEcore.py\u001b[0m in \u001b[0;36mgetJacobian\u001b[0;34m(self, xb, y)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxb_dist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb_disturbed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             self.y_disturbed.loc[xb_dist] = self.forward(\n\u001b[0;32m--> 292\u001b[0;31m                 self.xb_disturbed.loc[xb_dist], **self.forwardKwArgs)\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# create an empty jacobian matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-10562976deeb>\u001b[0m in \u001b[0;36mforwardRT\u001b[0;34m(X, myProfiles, ssmiRttov)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mssmiRttov\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunDirect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mpyrttov\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRttovError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error running RTTOV direct model: {!s}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/nwpsaf/rttov12/wrapper/pyrttov/__init__.py\u001b[0m in \u001b[0;36mrunDirect\u001b[0;34m(self, channels)\u001b[0m\n\u001b[1;32m    684\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_surfemisrefl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m         \u001b[0;31m# input/output surface emissivities/BRDFs                 [2][nprofiles][nchannels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bBasics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'btrefl'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0;31m# output BTs/refls (for thermal/solar chans)              [nprofiles][nchannels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bBasics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rads'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# output radiances                                        [nprofiles][nchannels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m                 )\n\u001b[1;32m    688\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_errCheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Error in rttov_call_direct'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "indexTotal = np.arange(len(prior_local.time)) # all time indices in prior_local [0,1,...16000,..] \n",
    "\n",
    "# Create copy of the indices array\n",
    "kk = np.copy(indexTotal)\n",
    "\n",
    "# Shuffle the indices array randomly\n",
    "np.random.shuffle(kk)\n",
    "\n",
    "# Split the array in K folds (for K-fold cross validation)\n",
    "K = 10\n",
    "hh = np.array_split(kk,K)\n",
    "\n",
    "rmse = 0.0\n",
    "mae = 0.0 #np.empty(0)\n",
    "r2 = 0.0 #np.empty(0)\n",
    "count = np.empty(0,dtype=int)\n",
    "wind_opt = np.empty(0)\n",
    "wind_true = np.empty(0)\n",
    "wind_opt_err = np.empty(0)\n",
    "\n",
    "KK = 0\n",
    "\n",
    "for indexTest in hh: \n",
    "    \n",
    "    KK += 1\n",
    "# How many \"situations\" do we want to test \n",
    "#(these will be split apart from the a-priori dataset).\n",
    "# Situation means a (Lat, Long, time) combination:\n",
    "# i.e. 1 Situation is one datapoint from the prior_local dataset\n",
    "    nTestSamples = len(indexTest) \n",
    "\n",
    "# The actual indices from prior_local  that will be used as testing points: \n",
    "# i.e. they are taken out of the a-priori data\n",
    "#indexTest = np.random.choice(indexTotal,nTestSamples) # This is used only if a Monte Carlo type of cross validation is done\n",
    "\n",
    "# The test indices are deleted from the a-priori (i.e. training) set\n",
    "    indexTrain = np.delete(indexTotal,indexTest)\n",
    "\n",
    "# Split available diverse datasets into:\n",
    "# - 5 profiles to generate synthetic data (profiles)\n",
    "# - Rest of the profiles to generate the prior \n",
    "# The 5 profiles for synthetic data are EXCLUDED from\n",
    "# the rest of the datasets (e.g. from the prior)\n",
    "\n",
    "    profiles = prior_local.isel(time=indexTest)\n",
    "    prior_local_1 = prior_local.isel(time=indexTrain)\n",
    "    \n",
    "    nLev = len(prior_local_1.height)\n",
    "    # Splitting the priors per season:\n",
    "    priors, pressure, seasons, months, h_season = supporting_routines_m.priors2seasons(prior_local_1) \n",
    "    # Converting priors per season to pandas dataframes:\n",
    "    #prior_xa, prior_wind = supporting_routines_m.priors2pandas(priors, \n",
    "    #                                                            wind_components = True, h_season = h_season)\n",
    "    \n",
    "    flavor = 2 # check \"priors2Pandas\"\n",
    "    prior_xa, prior_b = supporting_routines_m.priors2Pandas(priors, \n",
    "                                                                flavor = flavor, h_season = h_season)    \n",
    "    x_cov, x_mean = supporting_routines_m.meanCov(prior_xa, seasons)\n",
    "\n",
    "# Definition of the state variables (names of the variables)\n",
    "    x_vars = x_mean.state.values\n",
    "\n",
    "# Assert invertibility of the convariance matrices:\n",
    "    for season in x_cov.season:\n",
    "        assert np.linalg.matrix_rank(x_cov.sel(season=season).to_pandas()) ==  x_cov.shape[-1]\n",
    "        \n",
    "# Create x_truths: Pandas version of the profiles array (Containing only state variables!)\n",
    "    x_truths = supporting_routines_m.createTrueState(profiles, flavor=flavor)\n",
    "# Gather parameters for RTTOV from a-priori knowledge\n",
    "    \n",
    "    #prior_b = supporting_routines_m.b_fromPrior(priors)\n",
    "    \n",
    "# FOR RTTOV PARAMETERS\n",
    "# We use pandas tooling (cov, mean) to compute the mean\n",
    "# and covariance per season:  \n",
    "    b_cov, b_mean = supporting_routines_m.meanCov(prior_b, seasons)\n",
    "    b_vars = b_mean.state.values\n",
    "\n",
    "# Assert invertibility of the convariance matrices:\n",
    "    for season in x_cov.season:\n",
    "        assert np.linalg.matrix_rank(b_cov.sel(season=season).to_pandas()) ==  b_cov.shape[-1]   \n",
    "    \n",
    "    #w_op = np.zeros(len(indexTest))\n",
    "    #w_op_err = np.zeros(len(indexTest))\n",
    "    #w_a = np.zeros(len(indexTest))\n",
    "    #w_a_err = np.zeros(len(indexTest))\n",
    "    #w_truth = np.zeros(len(indexTest))\n",
    "    #chiSquareTest = np.array(len(indexTest), dtype=bool)\n",
    "    #linearityTest = np.array(len(indexTest), dtype=bool)\n",
    "    w_op2 = np.empty(0)\n",
    "    w_op_err2 = np.empty(0)\n",
    "    w_truth2 = np.empty(0)\n",
    "    u_op2 = np.empty(0)\n",
    "    u_op_err2 = np.empty(0)\n",
    "    u_truth2 = np.empty(0)\n",
    "    v_op2 = np.empty(0)\n",
    "    v_op_err2 = np.empty(0)\n",
    "    v_truth2 = np.empty(0)    \n",
    "    lat_local = np.empty(0)\n",
    "    long_local = np.empty(0)\n",
    "    lat_skip = np.empty(0)\n",
    "    long_skip = np.empty(0)\n",
    "    seasonal = np.empty(0,dtype=object)\n",
    "        \n",
    "    count_breaks = 0\n",
    "    count_nc = 0\n",
    "    for ind in np.arange(len(indexTest)):\n",
    "\n",
    "        prof = profiles.time.values[ind] \n",
    "        seasonIndex = int(np.where(np.isin(months,profiles['time.month'].values[ind]))[0])\n",
    "        season_prof = seasons[seasonIndex]\n",
    "\n",
    "# Profile used for generating synthetic observation:\n",
    "# Contains ONLY the to-be-retrieved parameters: \n",
    "# temperature, humidity, 10m surface windspeed\n",
    "        x_truth = x_truths.iloc[ind]\n",
    "\n",
    "# Other atmospheric parameters for the syntetic observation \n",
    "        #press2m = b_mean.sel(season=season_prof).values[0] \n",
    "        #temp2m = b_mean.sel(season=season_prof).values[1] \n",
    "# Check this choice for humidity at 2m height (hum2m), TODO *** mario\n",
    "        #hum2m = 10**(b_mean.sel(season=season_prof).values[2])/1000 \n",
    "      \n",
    "        #tskin = b_mean.sel(season=season_prof).values[3] \n",
    "\n",
    "        Pressure = pressure.loc[season_prof,:].values[:] \n",
    "\n",
    "# Other parameters needed for the radiative transfer model (RTTOV)\n",
    "        lat1 = np.float(profiles.lat.values[ind])\n",
    "        long1 = np.float(profiles.long.values[ind])\n",
    "        datetime_obs = prof\n",
    "        zenithAngle = 53.0\n",
    "        salinity = 35\n",
    "\n",
    "# Create instance of Profiles class; \n",
    "# it's a container of the input atmospheric state that RTTOV will simulate\n",
    "\n",
    "        myProfiles = pyrttov.Profiles(nprofiles, nlevels)\n",
    "\n",
    "# forward_b_init fills \"myProfiles\" with the \"fixed\" parameters for the RTTOV simulation.\n",
    "# The forward model F(x,b), RTTOV in our case, has two \"parameters\": x and b\n",
    "# x is the state vector that is being retrieved (as such it is allowed to change during the retrieval)\n",
    "# b contains all other parameters that are fixed during the retrieval (everything else that is not being retrieved)\n",
    "\n",
    "        forward_b_init(Pressure, salinity, \n",
    "              lat1, long1, datetime_obs, zenithAngle, myProfiles)\n",
    "        #forward_b_init(Pressure, press2m, temp2m, hum2m, tskin, salinity, \n",
    "        #      lat1, long1, datetime_obs, zenithAngle, myProfiles)\n",
    "        \n",
    "# Define a-priori information: mean and covariance matrix\n",
    "# for a given season (DJF, MAM, JJA, SON)\n",
    "\n",
    "        x_a = x_mean.sel(season=season_prof).to_pandas()[x_vars]\n",
    "        S_a = x_cov.sel(season=season_prof).to_pandas().loc[x_vars, x_vars]\n",
    "        \n",
    "        # Vector of parameters and its covariance:\n",
    "        b_p = b_mean.sel(season=season_prof).to_pandas()[b_vars]\n",
    "        S_b = b_cov.sel(season=season_prof).to_pandas().loc[b_vars, b_vars]\n",
    "            \n",
    "# Define dictionary of parameters for the forward model:\n",
    "\n",
    "        forwardKwArgs = dict(\n",
    "            myProfiles = myProfiles, \n",
    "            ssmiRttov = ssmiRttov\n",
    "        )\n",
    "\n",
    "# Call the forward model (i.e. creating synthetic obs.)\n",
    "\n",
    "        y_obs = forwardRT(x_truth, **forwardKwArgs)\n",
    "        y_obs = pn.Series(y_obs, index=y_vars)\n",
    "        assert np.all(np.isfinite(y_obs))\n",
    "        \n",
    "        y_K = KRT(x_truth, **forwardKwArgs)\n",
    "\n",
    "        #print('y_obs done') \n",
    "# Create optimalEstimation instance:\n",
    "\n",
    "        oe_ref = pyOE.optimalEstimation( # oe_1 if windDisambiguation used\n",
    "            x_vars, # state variable names\n",
    "            x_a,  # a priori\n",
    "            S_a, # a priori uncertainty\n",
    "            y_vars,  # measurement variable names\n",
    "            y_obs, # observations\n",
    "            S_y, # observation uncertainty\n",
    "            forwardRT, # forward Operator\n",
    "            forwardKwArgs=forwardKwArgs, # additonal function arguments\n",
    "            x_truth=x_truth, # true profile\n",
    "            b_vars=b_vars,   # Parameter vector variable names\n",
    "            b_p=b_p,        # Parameter vector \n",
    "            S_b=S_b        # Parameters error covariance matrix \n",
    "        )\n",
    "\n",
    "        #oe_1.doRetrieval()\n",
    "        oe_ref.doRetrieval()\n",
    "        \n",
    "        if not oe_ref.converged :  # oe_1 if windDisambiguation used\n",
    "            count_nc += 1\n",
    "            print('NO CONVERGENCE points:')\n",
    "            print(count_nc)\n",
    "            lat_skip = np.append(lat_skip,lat1)\n",
    "            long_skip = np.append(long_skip,long1)\n",
    "            continue\n",
    "\n",
    "        #oe_ref = windDisambiguation(oe_1,forwardRT,forwardKwArgs)  \n",
    "        \n",
    "# Not Including S_b, b_p:            \n",
    "        #_, _, w_op1 = supporting_routines_m.splitX(oe_ref.x_op)\n",
    "        #_, _, w_op_err1 = supporting_routines_m.splitX(oe_ref.x_op_err)\n",
    "        ##_, _, w_a[ind] = supporting_routines_m.splitX(oe_ref.x_a)\n",
    "        ##_, _, w_a_err[ind] = supporting_routines_m.splitX(oe_ref.x_a_err)\n",
    "        #_, _, w_truth1 = supporting_routines_m.splitX(oe_ref.x_truth)\n",
    "        \n",
    "    # U & V:\n",
    "        #_, _, u_op1, v_op1 = supporting_routines_m.splitXUV(oe_ref.x_op)\n",
    "        #_, _, u_op_err1, v_op_err1 = supporting_routines_m.splitXUV(oe_ref.x_op_err)\n",
    "        ##_, _, u_a1, v_a1 = supporting_routines_m.splitXUV(oe_ref.x_a)\n",
    "        ##_, _, u_a_err1, v_a_err1 = supporting_routines_m.splitXUV(oe_ref.x_a)\n",
    "        #_, _, u_truth1, v_truth1 = supporting_routines_m.splitXUV(oe_ref.x_truth) \n",
    "        #u_op2 = np.append(u_op2,u_op1)\n",
    "        #u_op_err2 = np.append(u_op_err2,u_op_err1)\n",
    "        #u_truth2 = np.append(u_truth2,u_truth1)\n",
    "        ## V component\n",
    "        #v_op2 = np.append(v_op2,v_op1)\n",
    "        #v_op_err2 = np.append(v_op_err2,v_op_err1)\n",
    "        #v_truth2 = np.append(v_truth2,v_truth1)          \n",
    "        ## Compute magnitude using coordinates U and V\n",
    "        ## w_op1 = np.sqrt( u_op1**2 + v_op1**2 )\n",
    "        #w_op1, w_op_err1 = supporting_routines_m.UV2Wvar(oe_ref.S_op.loc['00010_nu','00010_nu'],\n",
    "        #                                          oe_ref.S_op.loc['00010_nv','00010_nv'],\n",
    "        #                                          oe_ref.S_op.loc['00010_nu','00010_nv'],\n",
    "        #                                          u_op1,v_op1)\n",
    "        #w_truth1 = np.sqrt( u_truth1**2 + v_truth1**2 )        \n",
    "        \n",
    "# Including S_b, b_p:\n",
    "       # _,_, w_op1,_,_,_,_ = supporting_routines_m.splitXW_all(oe_ref.x_op)\n",
    "       # _,_, w_op_err1,_,_,_,_ = supporting_routines_m.splitXW_all(oe_ref.x_op_err)\n",
    "       ##_,_, w_a,_,_,_,_ = supporting_routines_m.splitXW_all(oe_ref.x_a)\n",
    "       ##_,_, w_a_err,_,_,_,_ = supporting_routines_m.splitXW_all(oe_ref.x_a_err)\n",
    "       # _,_, w_truth1,_,_,_,_ = supporting_routines_m.splitXW_all(oe_ref.x_truth)\n",
    "        \n",
    "    # U & V:\n",
    "        _,_,u_op1, v_op1,_,_,_ = supporting_routines_m.splitX_all(oe_ref.x_op)\n",
    "        _,_,u_op_err1, v_op_err1,_,_,_ = supporting_routines_m.splitX_all(oe_ref.x_op_err)\n",
    "        #_,_,u_a1, v_a1,_,_,_ = supporting_routines_m.splitX_all(oe_ref.x_a)\n",
    "        #_,_,u_a_err1, v_a_err1,_,_,_ = supporting_routines_m.splitX_all(oe_ref.x_a_err)\n",
    "        _,_,u_truth1, v_truth1,_,_,_ = supporting_routines_m.splitX_all(oe_ref.x_truth)\n",
    "        u_op2 = np.append(u_op2,u_op1)\n",
    "        u_op_err2 = np.append(u_op_err2,u_op_err1)\n",
    "        u_truth2 = np.append(u_truth2,u_truth1)\n",
    "        v_op2 = np.append(v_op2,v_op1)\n",
    "        v_op_err2 = np.append(v_op_err2,v_op_err1)\n",
    "        v_truth2 = np.append(v_truth2,v_truth1)          \n",
    "    # Compute magnitude using coordinates U and V\n",
    "        w_op1, w_op_err1 = supporting_routines_m.UV2Wvar(oe_ref.S_op.loc['00010_nu','00010_nu'],\n",
    "                                                  oe_ref.S_op.loc['00010_nv','00010_nv'],\n",
    "                                                  oe_ref.S_op.loc['00010_nu','00010_nv'],\n",
    "                                                  u_op1,v_op1)        \n",
    "        w_truth1 = np.sqrt( u_truth1**2 + v_truth1**2 )   \n",
    "        \n",
    "        # For wind components we compare absolute value only\n",
    "        # SSMIS cannot provide polarimetric measurements\n",
    "        # so comparing angular information is not a proper metric\n",
    "        # U component \n",
    "        \n",
    "\n",
    "        w_op2 = np.append(w_op2,w_op1)\n",
    "        w_op_err2 = np.append(w_op_err2,w_op_err1)\n",
    "        w_truth2 = np.append(w_truth2,w_truth1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        seasonal = np.append(seasonal,season_prof)\n",
    "        \n",
    "        lat_local = np.append(lat_local,lat1)\n",
    "        long_local = np.append(long_local,long1)\n",
    "        \n",
    "        print('index:')\n",
    "        print(ind)\n",
    "        \n",
    "    \n",
    "    plotInMap(lat_local, long_local, lat, long, KK, lat_skip, long_skip)\n",
    "    perSeasonPlots(w_truth2, w_op2, seasonal, KK, windType = 'W10m')\n",
    "    perSeasonPlots(u_truth2, u_op2, seasonal, KK, windType = 'U10m')\n",
    "    perSeasonPlots(v_truth2, v_op2, seasonal, KK, windType = 'V10m')\n",
    "    \n",
    "    rmse_local, mae_local, r2_local = regressPlots(w_truth2, w_op2, KK, windType = 'W10m')   \n",
    "    _, _, _ = regressPlots(u_truth2, u_op2, KK, windType = 'U10m')\n",
    "    _, _, _ = regressPlots(v_truth2, v_op2, KK, windType = 'V10m')\n",
    "    \n",
    "    rmse += rmse_local\n",
    "    mae += mae_local\n",
    "    r2 += r2_local\n",
    "    \n",
    "    #skipRatio = count_nc/(count_nc+len(w_op2)) # ratio of (skipped / total) points in the test dataset\n",
    "    \n",
    "    \n",
    "    \n",
    "    #if KK == 1: break\n",
    "\n",
    "rmse = rmse / KK\n",
    "mae = mae / KK\n",
    "r2 = r2 / KK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     218.001508\n",
       "2     241.558363\n",
       "3     233.654517\n",
       "4     224.389229\n",
       "5     219.285074\n",
       "6     218.480238\n",
       "7     218.673964\n",
       "12    106.142932\n",
       "13    176.481010\n",
       "14    187.519452\n",
       "15    138.060578\n",
       "16    202.009677\n",
       "23    235.468802\n",
       "24    223.442211\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oe_ref.S_op.loc[['00010_nu','00010_nv'],['00010_nu','00010_nv']]\n",
    "Uu2 = oe_ref.S_op.loc['00010_nu','00010_nu']  # variance U\n",
    "Uv2 = oe_ref.S_op.loc['00010_nv','00010_nv']  # variance V \n",
    "Uuv = oe_ref.S_op.loc['00010_nu','00010_nv']  # covariance UV\n",
    "\n",
    "u = np.float64(u_op1.values)\n",
    "v = np.float64(v_op1.values)\n",
    "w = np.sqrt(u**2+v**2)\n",
    "\n",
    "bruteUncertainty = np.sqrt(np.float64(u_op_err1.values)**2+np.float64(v_op_err1.values)**2)\n",
    "\n",
    "combinedUncertainty = np.sqrt((1/(w**2))*(Uu2*(u)**2+Uv2*(v)**2+2*u*v*Uuv))\n",
    "\n",
    "print(oe_ref.d_i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_vars[0] # state variable names\n",
    "#type(x_a)  # a priori\n",
    "#type(S_a), # a priori uncertainty\n",
    "#y_vars,  # measurement variable names\n",
    "#y_obs, # observations\n",
    "#S_y, # observation uncertainty\n",
    "b_vars,   # Parameter vector variable names\n",
    "#b_p,        # Parameter vector \n",
    "#S_b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#u, s, vh = np.linalg.svd(S_a, full_matrices=True)\n",
    "#plt.scatter(np.arange(len(s)),np.log10(np.absolute(s)/np.absolute(s[0])))\n",
    "#max_ind = 275\n",
    "#S_a2 = np.matmul(u[:,0:max_ind],np.matmul(np.diag(s[0:max_ind]),vh[0:max_ind,:]))\n",
    "#err = np.linalg.norm((S_a2-S_a),ord='fro') / np.linalg.norm((S_a),ord='fro')\n",
    "#print(err)\n",
    "#print(np.linalg.cond(S_a))\n",
    "#print(np.linalg.cond(S_a2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windDisambiguation(oe_ref,forwardRT,forwardKwArgs):\n",
    "    # Procedure proposed in:\n",
    "    # M. Bettenhausen, et al, \"A Nonlinear Optimization Algorithm \n",
    "    # for WindSat Wind Vector Retrievals\", IEEE Trans. Geo. Rem. Sens.,\n",
    "    # Vol. 44, No. 3, March 2006\n",
    "    \n",
    "    # First retrieved wind\n",
    "    #_, _, u_op, v_op = supporting_routines_m.splitXUV(oe_ref.x_op)\n",
    "    _,_,u_op, v_op,_,_,_ = supporting_routines_m.splitX_all(oe_ref.x_op)\n",
    "    \n",
    "    # Most of the retrieval parameters are the same as for the original retrieval:\n",
    "    x_vars = oe_ref.x_vars \n",
    "    y_vars = oe_ref.y_vars \n",
    "    y_obs = oe_ref.y_obs \n",
    "    S_a = oe_ref.S_a\n",
    "    S_y = oe_ref.S_y\n",
    "    \n",
    "    S_b = oe_ref.S_b\n",
    "    b_vars = oe_ref.b_vars\n",
    "    b_p = oe_ref.b_p\n",
    "    \n",
    "    #forwardRT = oe_ref.forwardRT\n",
    "    #forwardKwArgs = oe_ref.forwardKwArgs\n",
    "    x_truth = oe_ref.x_truth \n",
    "    \n",
    "    mini = 100000\n",
    "    \n",
    "    rot = np.array([[0,-1],[1,0]]) # Rotation matrix (90 deg rotation)\n",
    "    # 4 ambiguities (1 per quadrant):\n",
    "    aprio1 = np.array([[np.float64(u_op.values)],[np.float64(v_op.values)]])   \n",
    "    aprio2 = np.dot(rot,aprio1)\n",
    "    aprio3 = np.dot(rot,aprio2)\n",
    "    aprio4 = np.dot(rot,aprio3)\n",
    "    \n",
    "    # Re-use the first retrieved atmospheric state as the new a-priori dataset\n",
    "    x_a1 = oe_ref.x_op.copy()\n",
    "    x_a1['00010_nu'] = aprio1[0,0] # a-priori wind 1: as retrieved\n",
    "    x_a1['00010_nv'] = aprio1[1,0]\n",
    "    oe_ref1 = pyOE.optimalEstimation(\n",
    "            x_vars, # state variable names\n",
    "            x_a1,  # a priori\n",
    "            S_a, # a priori uncertainty\n",
    "            y_vars,  # measurement variable names\n",
    "            y_obs, # observations\n",
    "            S_y, # observation uncertainty\n",
    "            forwardRT, # forward Operator\n",
    "            forwardKwArgs=forwardKwArgs, # additonal function arguments\n",
    "            x_truth=x_truth, # true profile\n",
    "            b_vars=b_vars,   # Parameter vector variable names\n",
    "            b_p=b_p,        # Parameter vector \n",
    "            S_b=S_b        # Parameters error covariance matrix \n",
    "            )\n",
    "\n",
    "    oe_ref1.doRetrieval()\n",
    "    \n",
    "    # X**2 (eq (2) in reference), goodness of fit of forward model:\n",
    "    # TODO: S_y should be S_y+S_b' # note Mario    \n",
    "    numero = np.dot(np.transpose(y_obs-oe_ref1.y_i[-1]),\n",
    "                    np.dot(np.linalg.inv(oe_ref1.S_y),\n",
    "                           (y_obs-oe_ref1.y_i[-1])))\n",
    "    #if oe_ref1.d_i2[-1]<mini:\n",
    "    if numero < mini:\n",
    "        mini = numero #oe_ref1.d_i2[-1]\n",
    "        oe_return = oe_ref1\n",
    "        index = 1\n",
    "        \n",
    "    #_, _,u1, v1 = supporting_routines_m.splitXUV(oe_ref1.x_op)\n",
    "# 2nd vector\n",
    "    x_a2 = oe_ref.x_op.copy()\n",
    "    x_a2['00010_nu'] = aprio2[0,0]\n",
    "    x_a2['00010_nv'] = aprio2[1,0]\n",
    "    oe_ref2 = pyOE.optimalEstimation(\n",
    "            x_vars, # state variable names\n",
    "            x_a2,  # a priori\n",
    "            S_a, # a priori uncertainty\n",
    "            y_vars,  # measurement variable names\n",
    "            y_obs, # observations\n",
    "            S_y, # observation uncertainty\n",
    "            forwardRT, # forward Operator\n",
    "            forwardKwArgs=forwardKwArgs, # additonal function arguments\n",
    "            x_truth=x_truth, # true profile\n",
    "            b_vars=b_vars,   # Parameter vector variable names\n",
    "            b_p=b_p,        # Parameter vector \n",
    "            S_b=S_b        # Parameters error covariance matrix \n",
    "            )\n",
    "\n",
    "    oe_ref2.doRetrieval()\n",
    "    \n",
    "    # X**2 (eq (2) in reference), goodness of fit of forward model:\n",
    "    # TODO: S_y should be S_y+S_b' # note Mario\n",
    "    numero = np.dot(np.transpose(y_obs-oe_ref2.y_i[-1]),\n",
    "                    np.dot(np.linalg.inv(oe_ref2.S_y),\n",
    "                           (y_obs-oe_ref2.y_i[-1])))    \n",
    "    #if oe_ref2.d_i2[-1]<mini:\n",
    "    if numero < mini:\n",
    "        mini = numero #oe_ref2.d_i2[-1]\n",
    "        oe_return = oe_ref2\n",
    "        index = 2\n",
    "        \n",
    "    #_, _,u2, v2 = supporting_routines_m.splitXUV(oe_ref2.x_op)\n",
    "# 3rd vector\n",
    "    x_a3= oe_ref.x_op.copy()\n",
    "    x_a3['00010_nu'] = aprio3[0,0]\n",
    "    x_a3['00010_nv'] = aprio3[1,0]\n",
    "    oe_ref3 = pyOE.optimalEstimation(\n",
    "            x_vars, # state variable names\n",
    "            x_a3,  # a priori\n",
    "            S_a, # a priori uncertainty\n",
    "            y_vars,  # measurement variable names\n",
    "            y_obs, # observations\n",
    "            S_y, # observation uncertainty\n",
    "            forwardRT, # forward Operator\n",
    "            forwardKwArgs=forwardKwArgs, # additonal function arguments\n",
    "            x_truth=x_truth, # true profile\n",
    "            b_vars=b_vars,   # Parameter vector variable names\n",
    "            b_p=b_p,        # Parameter vector \n",
    "            S_b=S_b        # Parameters error covariance matrix \n",
    "            )\n",
    "\n",
    "    oe_ref3.doRetrieval()\n",
    "    \n",
    "    # X**2 (eq (2) in reference), goodness of fit of forward model:\n",
    "    # TODO: S_y should be S_y+S_b' # note Mario    \n",
    "    numero = np.dot(np.transpose(y_obs-oe_ref3.y_i[-1]),\n",
    "                    np.dot(np.linalg.inv(oe_ref3.S_y),\n",
    "                           (y_obs-oe_ref3.y_i[-1])))     \n",
    "    \n",
    "    #if oe_ref3.d_i2[-1]<mini:\n",
    "    if numero < mini:\n",
    "        mini = numero #oe_ref3.d_i2[-1]\n",
    "        oe_return = oe_ref3\n",
    "        index = 3\n",
    "        \n",
    "    #_, _,u3, v3 = supporting_routines_m.splitXUV(oe_ref3.x_op)\n",
    "# 4th vector\n",
    "    x_a4 = oe_ref.x_op.copy()\n",
    "    x_a4['00010_nu'] = aprio4[0,0]\n",
    "    x_a4['00010_nv'] = aprio4[1,0]\n",
    "    oe_ref4 = pyOE.optimalEstimation(\n",
    "            x_vars, # state variable names\n",
    "            x_a4,  # a priori\n",
    "            S_a, # a priori uncertainty\n",
    "            y_vars,  # measurement variable names\n",
    "            y_obs, # observations\n",
    "            S_y, # observation uncertainty\n",
    "            forwardRT, # forward Operator\n",
    "            forwardKwArgs=forwardKwArgs, # additonal function arguments\n",
    "            x_truth=x_truth, # true profile\n",
    "            b_vars=b_vars,   # Parameter vector variable names\n",
    "            b_p=b_p,        # Parameter vector \n",
    "            S_b=S_b        # Parameters error covariance matrix \n",
    "            )\n",
    "\n",
    "    oe_ref4.doRetrieval()\n",
    "    \n",
    "    # X**2 (eq (2) in reference), goodness of fit of forward model:\n",
    "    # TODO: S_y should be S_y+S_b' # note Mario\n",
    "    numero = np.dot(np.transpose(y_obs-oe_ref4.y_i[-1]),\n",
    "                    np.dot(np.linalg.inv(oe_ref4.S_y),\n",
    "                           (y_obs-oe_ref4.y_i[-1])))     \n",
    "    \n",
    "    #if oe_ref4.d_i2[-1]<mini:\n",
    "    if numero < mini:\n",
    "        mini = numero #oe_ref4.d_i2[-1]\n",
    "        oe_return = oe_ref4\n",
    "        index = 4\n",
    "        \n",
    "    #_, _,u4, v4 = supporting_routines_m.splitXUV(oe_ref4.x_op)\n",
    "    print(index)\n",
    "\n",
    "    return oe_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f, ax = plt.subplots(figsize=(9, 6))\n",
    "#sns.heatmap(S_a, ax=ax, cbar_kws={'label':'Covariance [K$^2$]'})\n",
    "#ax.set_title('$\\mathbb{S}_{a}$ Temperature')\n",
    "#plt.savefig('Test_Sa.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardRT(X, myProfiles, ssmiRttov):\n",
    "    \n",
    "    # TODO: Add assertions, tests *** mario\n",
    "\n",
    "    # X contains T, Q and W10, lets split the vector\n",
    "    #temperature, humidity, wind10m = supporting_routines_m.splitX(X)\n",
    "    \n",
    "    # if wind speed in components:\n",
    "    #temperature, humidity, u10m, v10m = supporting_routines_m.splitXUV(X)\n",
    "    temperature, humidity, u10m, v10m, bp2m, bt2m, btsk = supporting_routines_m.splitX_all(X)\n",
    "    #temperature, humidity, wind10m, bp2m, bt2m, btsk = supporting_routines_m.splitXW_all(X)\n",
    "    \n",
    "    # humdity is in log10 scale, convert to linear in kg/kg\n",
    "    humidity = (10**humidity) / 1000.\n",
    "    # or abs_humidity? *** note mario\n",
    "    \n",
    "    #hum2m = 10**(np.float64(bh2m.values))/1000 \n",
    "    \n",
    "    myProfiles.T = expand2nprofiles(np.array(temperature.values,dtype=np.float64), nprofiles)\n",
    "    myProfiles.Q = expand2nprofiles(np.array(humidity.values,dtype=np.float64), nprofiles)  \n",
    "\n",
    "    myProfiles.S2m[0,0] = np.float64(bp2m.values) # surface pressure\n",
    "    myProfiles.S2m[0,1] = np.float64(bt2m.values) # 2m temperature\n",
    "    #myProfiles.S2m[0,2] = hum2m                   # 2m humidity, is not mandatory for RTTOV\n",
    "    myProfiles.Skin[0,0] = np.float64(btsk.values)\n",
    "    \n",
    "    #myProfiles.S2m[0,3] = np.float64(wind10m.values) / ( np.sqrt(2) ) #  10m windspeed, u component\n",
    "    #myProfiles.S2m[0,4] = np.float64(wind10m.values) / ( np.sqrt(2) ) #  10m windspeed, v component\n",
    "    \n",
    "    # if wind in components:\n",
    "    myProfiles.S2m[0,3] = np.float64(u10m.values) #  10m windspeed, u component\n",
    "    myProfiles.S2m[0,4] = np.float64(v10m.values) #  10m windspeed, v component  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ssmiRttov.Profiles = myProfiles\n",
    "    \n",
    "    ssmiRttov.SurfEmisRefl[:,:,:] = -1. # need to \"reset\" to -1 every time RTTOV is called; \n",
    "    # -1 indicates to RTTOV to use internal values for surface emissivity.\n",
    "    \n",
    "    try:\n",
    "        ssmiRttov.runDirect()\n",
    "    except pyrttov.RttovError as e:\n",
    "        sys.stderr.write(\"Error running RTTOV direct model: {!s}\".format(e))\n",
    "        sys.exit(1)    \n",
    "        \n",
    "    TB = ssmiRttov.BtRefl[0, :]\n",
    "    \n",
    "    return TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KRT(X, myProfiles, ssmiRttov):\n",
    "    \n",
    "    # TODO: Add assertions, tests *** mario\n",
    "\n",
    "    # X contains T, Q and W10, lets split the vector\n",
    "    #temperature, humidity, wind10m = supporting_routines_m.splitX(X)\n",
    "    \n",
    "    # if wind speed in components:\n",
    "    #temperature, humidity, u10m, v10m = supporting_routines_m.splitXUV(X)\n",
    "    temperature, humidity, u10m, v10m, bp2m, bt2m, btsk = supporting_routines_m.splitX_all(X)\n",
    "    #temperature, humidity, wind10m, bp2m, bt2m, btsk = supporting_routines_m.splitXW_all(X)\n",
    "    \n",
    "    # humdity is in log10 scale, convert to linear in kg/kg\n",
    "    humidity = (10**humidity) / 1000.\n",
    "    # or abs_humidity? *** note mario\n",
    "    \n",
    "    #hum2m = 10**(np.float64(bh2m.values))/1000 \n",
    "    \n",
    "    myProfiles.T = expand2nprofiles(np.array(temperature.values,dtype=np.float64), nprofiles)\n",
    "    myProfiles.Q = expand2nprofiles(np.array(humidity.values,dtype=np.float64), nprofiles)  \n",
    "\n",
    "    myProfiles.S2m[0,0] = np.float64(bp2m.values) # surface pressure\n",
    "    myProfiles.S2m[0,1] = np.float64(bt2m.values) # 2m temperature\n",
    "    #myProfiles.S2m[0,2] = hum2m                   # 2m humidity, is not mandatory for RTTOV\n",
    "    myProfiles.Skin[0,0] = np.float64(btsk.values)\n",
    "    \n",
    "    #myProfiles.S2m[0,3] = np.float64(wind10m.values) / ( np.sqrt(2) ) #  10m windspeed, u component\n",
    "    #myProfiles.S2m[0,4] = np.float64(wind10m.values) / ( np.sqrt(2) ) #  10m windspeed, v component\n",
    "    \n",
    "    # if wind in components:\n",
    "    myProfiles.S2m[0,3] = np.float64(u10m.values) #  10m windspeed, u component\n",
    "    myProfiles.S2m[0,4] = np.float64(v10m.values) #  10m windspeed, v component  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ssmiRttov.Profiles = myProfiles\n",
    "    \n",
    "    ssmiRttov.SurfEmisRefl[:,:,:] = -1. # need to \"reset\" to -1 every time RTTOV is called; \n",
    "    # -1 indicates to RTTOV to use internal values for surface emissivity.\n",
    "    \n",
    "    try:\n",
    "        ssmiRttov.runK()\n",
    "    except pyrttov.RttovError as e:\n",
    "        sys.stderr.write(\"Error running RTTOV K model: {!s}\".format(e))\n",
    "        sys.exit(1)    \n",
    "        \n",
    "    TB = ssmiRttov.BtRefl[:, :]\n",
    "    \n",
    "    return TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand2nprofiles(n, nprof):\n",
    "    # Transform 1D array to a [nprof, nlevels] array\n",
    "    outp = np.empty((nprof, len(n)), dtype=n.dtype)\n",
    "    for i in range(nprof):\n",
    "        outp[i, :] = n[:]\n",
    "    return outp\n",
    "\n",
    "\n",
    "def forward_b_init(pressure, salinity, lat, long, datetime_obs64, \n",
    "                   zenithAngle, myProfiles):\n",
    "#def forward_b_init(pressure, press2m, temp2m, hum2m, tskin, salinity, \n",
    "#              lat, long, datetime_obs64, zenithAngle, myProfiles):\n",
    "    \n",
    "    \n",
    "    nprofiles = 1 # Hardcoded for now; to be used in a retrieval framework (e.g.\n",
    "    #  analyze 1 profile at the time); bad choice, to change. TODO *** mario  \n",
    "    \n",
    "    # The rest of the code uses datetime64 format (numpy), but I have to pass the obs date as integers to RTTOV\n",
    "    datetime_obs = supporting_routines_m.datetime64_to_datetime(datetime_obs64)\n",
    "    \n",
    "    \n",
    "    # 10m wind speed is an unknown parameter to be retrieved (is part of x not of b):\n",
    "    s2m = np.array([[0., 0., 0., 0., 0., 0.]], dtype=np.float64)\n",
    "    #s2m = np.array([[press2m, temp2m, hum2m, 0., 0., 0.]], dtype=np.float64)\n",
    "    \n",
    "    angles = np.array([[zenithAngle,  0., 0., 0.]], dtype=np.float64)\n",
    "    \n",
    "    skin = np.array([[0., salinity, 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=np.float64)\n",
    "    #skin = np.array([[tskin, salinity, 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=np.float64)\n",
    "    \n",
    "    surftype = np.array([[1, 1]], dtype=np.int32) # [sea, ocean] Harcoded for now, TODO *** mario\n",
    "    \n",
    "    surfgeom = np.array([[lat, long, 0.]], dtype=np.float64) # elevation harcoded to 0 for now, TODO *** mario\n",
    "    \n",
    "    date_times = np.array([[datetime_obs.year, datetime_obs.month, datetime_obs.day,\n",
    "                            datetime_obs.hour, datetime_obs.minute, datetime_obs.second]], dtype=np.int32)\n",
    "    \n",
    "    \n",
    "    myProfiles.GasUnits = 1  # kg/kg (see RTTOV doc. for other options) # Harcoded for now, TODO *** mario\n",
    "    myProfiles.P = expand2nprofiles(pressure, nprofiles)\n",
    "    myProfiles.S2m = s2m\n",
    "    myProfiles.Angles = angles\n",
    "    myProfiles.Skin = skin\n",
    "    myProfiles.SurfType = surftype\n",
    "    myProfiles.SurfGeom = surfgeom\n",
    "    myProfiles.DateTimes = date_times\n",
    "    \n",
    "    #return myProfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotInMap(lat2, long2, lat, long, indice, lat_s = None, long_s = None):\n",
    "    \n",
    "    #lat2 = profiles.lat.values\n",
    "    #long2 = profiles.long.values\n",
    "\n",
    "    plt.figure(figsize=(13,6.2))\n",
    "    \n",
    "    ax = plt.subplot(111, projection=ccrs.PlateCarree())\n",
    "\n",
    "    ax.scatter(long,\\\n",
    "                   lat,marker='.',color='red')\n",
    "    ax.scatter(long2,\\\n",
    "                   lat2,marker='o',color='blue')\n",
    "    if (lat_s is not None)and(long_s is not None):\n",
    "        ax.scatter(long_s,\\\n",
    "                   lat_s,marker='o',color='yellow')\n",
    "                \n",
    "    ax.coastlines();\n",
    "\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax.set_xlabel('Longitude [deg]')\n",
    "    ax.set_ylabel('Latitude [deg]')\n",
    "\n",
    "    ax.stock_img();\n",
    "\n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(), linewidth=2, \n",
    "                      color='black', alpha=0.5, linestyle='--', draw_labels=True)\n",
    "    gl.xlabels_top = False\n",
    "    gl.ylabels_left = False\n",
    "    gl.ylabels_right=True\n",
    "    gl.xlines = True\n",
    "    gl.xlocator = mticker.FixedLocator([-180, -120, -60, 0, 60, 120, 180])\n",
    "    gl.ylocator = mticker.FixedLocator([-60, -30, 0, 30, 60])\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "\n",
    "    plt.savefig('Loc_Fold_'+str(indice)+'.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perSeasonPlots(truth,optimized,seasonal, indice, windType = 'W10m'):\n",
    "    \n",
    "    colors = {'DJF':'blue', 'MAM':'green', 'JJA':'orange', 'SON':'purple'}\n",
    "    \n",
    "    df = pn.DataFrame(dict(Truth=truth, Optimized=optimized, Season = seasonal))\n",
    "    \n",
    "    seasonGroup = df.groupby('Season')\n",
    "\n",
    "    for name, group in seasonGroup:\n",
    "        #print name\n",
    "        #print group \n",
    "        \n",
    "        w_truth = group['Truth'].values[:]\n",
    "        w_opt = group['Optimized'].values[:]\n",
    "\n",
    "        error_local = w_truth - w_opt\n",
    "        mean_error_local = np.mean( error_local )\n",
    "        median_error_local = np.median( error_local )\n",
    "        multiplicativeBias = np.mean(w_truth) / np.mean(w_opt)\n",
    "\n",
    "        rmse_local = np.sqrt(mean_squared_error(w_truth, w_opt)) \n",
    "        mae_local = median_absolute_error(w_truth, w_opt)\n",
    "        r2_local = r2_score(w_truth, w_opt)\n",
    "\n",
    "        \n",
    "        wt = np.reshape( w_truth, (len(w_truth),1) ) # for using with .fit below\n",
    "        \n",
    "        # Ordinary least squares:\n",
    "        regr = LinearRegression()\n",
    "    \n",
    "        # Robust fit with Ransac algo. (sklearn lib.)\n",
    "        ransac = RANSACRegressor()\n",
    "        \n",
    "        # HuberRegressor\n",
    "        #huber = HuberRegressor()\n",
    "\n",
    "        # Train the model using the training sets\n",
    "        \n",
    "            # OLS fit:\n",
    "        regr.fit(wt, w_opt)\n",
    "        # Ransac fit:\n",
    "        ransac.fit(wt, w_opt)\n",
    "        # Huber fit\n",
    "        #huber.fit(wt, w_opt)\n",
    "        \n",
    "        # mask inlier-outlier from Ransac:\n",
    "        inlier_mask = ransac.inlier_mask_\n",
    "        outlier_mask = np.logical_not(inlier_mask)\n",
    "        \n",
    "        # mask inlier-outlier from Huber:     \n",
    "        #outlier_mask = huber.outliers_\n",
    "        #inlier_mask = np.logical_not(outlier_mask)\n",
    "    \n",
    "        # Make predictions using the testing set\n",
    "        # OLS:\n",
    "        wind_pred = regr.predict(wt)  \n",
    "        # Ransac:\n",
    "        wind_ransac = ransac.predict(wt)\n",
    "        # Huber:\n",
    "        #wind_huber = huber.predict(wt)   \n",
    "    \n",
    "        fig, (ax1,ax2) = plt.subplots(ncols=2, sharey = True)\n",
    "        # Plot outputs\n",
    "        ax1.scatter(w_truth, w_opt,  c=group['Season'].map(colors), alpha= 0.5, label = 'Optimal vs True')\n",
    "        ax1.plot(w_truth, wind_pred, color='black', linewidth=1.5, label = 'Linear regression')\n",
    "        ax1.plot(w_truth, w_truth, color='gray', linewidth=1.5, label = 'Slope 1 line')\n",
    "\n",
    "        ax1.set_ylabel('NS Wind Speed [m/s], Retrieved')\n",
    "        ax1.set_xlabel('NS Wind Speed [m/s], True')\n",
    "        ax1.grid(True)\n",
    "        ax1.set_title('OLS '+windType)\n",
    "        ax1.text(\n",
    "            0.95,\n",
    "            0.05,\n",
    "            '%s\\nm = %.3g\\nb = %.3g%s\\nrmse = %.3g%s\\nmae = %.3g%s\\nr$^2$ = %.3g' % (\n",
    "                '$mx+b$',\n",
    "                np.float(regr.coef_),\n",
    "                np.float(regr.intercept_),'m/s',\n",
    "                rmse_local,'m/s',\n",
    "                mae_local,'m/s',\n",
    "                r2_local),\n",
    "            horizontalalignment='right',\n",
    "            verticalalignment='bottom',\n",
    "            transform=ax1.transAxes)\n",
    "        \n",
    "        # Plot Ransac\n",
    "        ax2.scatter(w_truth[inlier_mask], w_opt[inlier_mask],  \n",
    "                c=group['Season'][inlier_mask].map(colors), alpha = 0.5, label = 'Retrieved')\n",
    "        ax2.scatter(w_truth[outlier_mask], w_opt[outlier_mask],  \n",
    "                color='magenta', alpha = 0.4, label = 'Outlier')\n",
    "        ax2.plot(w_truth, wind_ransac, color='black', linewidth=1.5, label = 'Regression')\n",
    "        ax2.plot(w_truth, w_truth, color='gray', linewidth=1.5, label = 'm = 1')\n",
    "    \n",
    "        ax2.legend()\n",
    "        ax2.set_xlabel('NS Wind Speed [m/s], True')\n",
    "        ax2.grid(True)\n",
    "        ax2.set_title('Ransac '+windType)\n",
    "        ax2.text(\n",
    "            0.95,\n",
    "            0.05,\n",
    "            '%s\\nm = %.3g\\nb = %.3g%s\\nrmse = %.3g%s\\nmae = %.3g%s\\nr$^2$ = %.3g' % (\n",
    "                '$mx+b$',\n",
    "                np.float(ransac.estimator_.coef_),\n",
    "                np.float(ransac.estimator_.intercept_),'m/s',\n",
    "                np.sqrt(mean_squared_error(w_truth[inlier_mask], w_opt[inlier_mask])) ,'m/s',\n",
    "                median_absolute_error(w_truth[inlier_mask], w_opt[inlier_mask]),'m/s',\n",
    "                np.float(r2_score(w_truth[inlier_mask], w_opt[inlier_mask]))),\n",
    "            horizontalalignment='right',\n",
    "            verticalalignment='bottom',\n",
    "            transform=ax2.transAxes)\n",
    "\n",
    "        plt.legend(loc=(0.02,0.73), prop={'size': 9}) \n",
    "        plt.savefig('seas_wind'+name+windType+'_'+str(indice), dpi=300)  \n",
    "        \n",
    "        # Histogram\n",
    "        bins_all = 5\n",
    "\n",
    "        fig, ax = plt.subplots(1)\n",
    "        ax.hist(error_local, bins = bins_all, label=name)\n",
    "        ax.legend()\n",
    "        ax.text(0.95,0.75,\n",
    "                'Mean error = %.3g\\nMedian error = %.3g\\nBias (M) = %.3g' % ( \n",
    "                    mean_error_local, \n",
    "                    median_error_local,\n",
    "                    multiplicativeBias),\n",
    "                horizontalalignment='right',\n",
    "                verticalalignment='top',\n",
    "                transform=ax.transAxes)\n",
    "    \n",
    "        ax.grid(True)\n",
    "        plt.savefig('seas_err'+name+windType+'_'+str(indice), dpi=300)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressPlots(truth, optimized, indice, windType = 'Wind'):\n",
    "    \n",
    "        #error_local = truth - optimized\n",
    "        #mean_error_local = np.mean( error_local )\n",
    "        #median_error_local = np.median( error_local )\n",
    "    \n",
    "        rmse_local = np.sqrt(mean_squared_error(truth, optimized)) \n",
    "        mae_local = median_absolute_error(truth, optimized)\n",
    "        r2_local = r2_score(truth, optimized)\n",
    "\n",
    "    \n",
    "        # Ordinary least squares:\n",
    "        regr = LinearRegression()\n",
    "    \n",
    "        # Robust fit with Ransac algo. (sklearn lib.)\n",
    "        ransac = RANSACRegressor()\n",
    "    \n",
    "        # Train the model using the training sets\n",
    "        wt = np.reshape(truth,(len(truth),1)) # for using with .fit below\n",
    "    \n",
    "        # OLS fit:\n",
    "        regr.fit(wt, optimized)\n",
    "        # Ransac fit:\n",
    "        ransac.fit(wt, optimized)\n",
    "        # mask inlier-outlier from Ransac:\n",
    "        inlier_mask = ransac.inlier_mask_\n",
    "        outlier_mask = np.logical_not(inlier_mask)\n",
    "    \n",
    "        # Make predictions using the testing set\n",
    "        # OLS:\n",
    "        wind_pred = regr.predict(wt)  \n",
    "        # Ransac:\n",
    "        wind_ransac = ransac.predict(wt)\n",
    "    \n",
    "        fig, (ax1,ax2) = plt.subplots(ncols=2, sharey = True)\n",
    "        # Plot outputs\n",
    "        ax1.scatter(truth, optimized,  color='dodgerblue', alpha = 0.5, label = 'Optimal vs True')\n",
    "        ax1.plot(truth, wind_pred, color='black', linewidth=1.5, label = 'Linear regression')\n",
    "        ax1.plot(truth, truth, color='gray', linewidth=1.5, label = 'Slope 1 line')\n",
    "\n",
    "        ax1.set_ylabel('NS Wind Speed [m/s], Retrieved')\n",
    "        ax1.set_xlabel('NS Wind Speed [m/s], True')\n",
    "        ax1.grid(True)\n",
    "        ax1.set_title('OLS '+windType)\n",
    "        ax1.text(\n",
    "            0.95,\n",
    "            0.05,\n",
    "            '%s\\nm = %.3g\\nb = %.3g%s\\nrmse = %.3g%s\\nmae = %.3g%s\\nr$^2$ = %.3g' % (\n",
    "            '$mx+b$',\n",
    "            np.float(regr.coef_),\n",
    "            np.float(regr.intercept_),'m/s',\n",
    "            rmse_local,'m/s',\n",
    "            mae_local,'m/s',\n",
    "            r2_local),\n",
    "            horizontalalignment='right',\n",
    "            verticalalignment='bottom',\n",
    "            transform=ax1.transAxes)\n",
    "\n",
    "        # Plot outputs\n",
    "        ax2.scatter(truth[inlier_mask], optimized[inlier_mask],  \n",
    "                color='dodgerblue', alpha = 0.5, label = 'Retrieved')\n",
    "        ax2.scatter(truth[outlier_mask], optimized[outlier_mask],  \n",
    "                color='magenta', alpha = 0.5, label = 'Outlier')\n",
    "        ax2.plot(truth, wind_ransac, color='black', linewidth=1.5, label = 'Regression')\n",
    "        ax2.plot(truth, truth, color='gray', linewidth=1.5, label = 'm = 1')\n",
    "    \n",
    "        ax2.legend()\n",
    "        ax2.set_xlabel('NS Wind Speed [m/s], True')\n",
    "        ax2.grid(True)\n",
    "        ax2.set_title('Ransac '+windType)\n",
    "        ax2.text(\n",
    "            0.95,\n",
    "            0.05,\n",
    "            '%s\\nm = %.3g\\nb = %.3g%s\\nrmse = %.3g%s\\nmae = %.3g%s\\nr$^2$ = %.3g' % (\n",
    "            '$mx+b$',\n",
    "            np.float(ransac.estimator_.coef_),\n",
    "            np.float(ransac.estimator_.intercept_),'m/s',\n",
    "            np.sqrt(mean_squared_error(truth[inlier_mask], optimized[inlier_mask])) ,'m/s',\n",
    "            median_absolute_error(truth[inlier_mask], optimized[inlier_mask]),'m/s',\n",
    "            np.float(r2_score(truth[inlier_mask], optimized[inlier_mask]))),\n",
    "            horizontalalignment='right',\n",
    "            verticalalignment='bottom',\n",
    "            transform=ax2.transAxes)\n",
    "\n",
    "        plt.legend(loc=(0.02,0.73), prop={'size': 9}) \n",
    "        plt.savefig('windR_'+windType+str(indice), dpi=300)\n",
    "        \n",
    "        return rmse_local, mae_local, r2_local\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(9, 6))\n",
    "sns.heatmap(\n",
    "    S_y.where(S_y > 0), \n",
    "    annot=True, \n",
    "    fmt='.2f', \n",
    "    ax=ax, \n",
    "    linewidths=.05, \n",
    "    cbar_kws={'label':'Covariance [K$^2$]'}\n",
    ")\n",
    "ax.set_title(r'Measurement uncertainty $\\mathbf{S}_{y}$')\n",
    "plt.savefig('Sy_1-7_12-16_23-24', dpi=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Here inner loop should start:\n",
    "\n",
    "w_op = np.zeros(len(indexTest))\n",
    "w_op_err = np.zeros(len(indexTest))\n",
    "w_a = np.zeros(len(indexTest))\n",
    "w_a_err = np.zeros(len(indexTest))\n",
    "w_truth = np.zeros(len(indexTest))\n",
    "chiSquareTest = np.array(len(indexTest), dtype=bool)\n",
    "linearityTest = np.array(len(indexTest), dtype=bool)\n",
    "\n",
    "for ind in np.arange(len(indexTest)):\n",
    "\n",
    "    prof = profiles.time.values[ind] \n",
    "    seasonIndex = int(np.where(np.isin(months,profiles['time.month'].values[ind]))[0])\n",
    "    season_prof = seasons[seasonIndex]\n",
    "\n",
    "# Profile used for generating synthetic observation:\n",
    "# Contains ONLY the to-be-retrieved parameters: \n",
    "# temperature, humidity, 10m surface windspeed\n",
    "    x_truth = x_truths.iloc[ind]\n",
    "\n",
    "# Other atmospheric parameters for the syntetic observation \n",
    "    press2m = b_mean.sel(season=season_prof).values[0] \n",
    "    temp2m = b_mean.sel(season=season_prof).values[1] \n",
    "# Check this choice for humidity at 2m height (hum2m), TODO *** mario\n",
    "    hum2m = 10**(b_mean.sel(season=season_prof).values[2])/1000 \n",
    "    tskin = b_mean.sel(season=season_prof).values[3] \n",
    "\n",
    "    Pressure = pressure.loc[season_prof,:].values[:] \n",
    "\n",
    "# Other parameters needed for the radiative transfer model (RTTOV)\n",
    "    lat1 = np.float(profiles.lat.values[ind])\n",
    "    long1 = np.float(profiles.long.values[ind])\n",
    "    datetime_obs = prof\n",
    "    zenithAngle = 53.0\n",
    "    salinity = 35\n",
    "\n",
    "# Create instance of Profiles class; \n",
    "# it's a container of the input atmospheric state that RTTOV will simulate\n",
    "\n",
    "    myProfiles = pyrttov.Profiles(nprofiles, nlevels)\n",
    "\n",
    "# forward_b_init fills \"myProfiles\" with the \"fixed\" parameters for the RTTOV simulation.\n",
    "# The forward model F(x,b), RTTOV in our case, has two \"parameters\": x and b\n",
    "# x is the state vector that is being retrieved (as such it is allowed to change during the retrieval)\n",
    "# b contains all other parameters that are fixed during the retrieval (everything else that is not being retrieved)\n",
    "\n",
    "    forward_b_init(Pressure, press2m, temp2m, hum2m, tskin, salinity, \n",
    "              lat1, long1, datetime_obs, zenithAngle, 1, nlevels, myProfiles)\n",
    "\n",
    "# Define a-priori information: mean and covariance matrix\n",
    "# for a given season (DJF, MAM, JJA, SON)\n",
    "\n",
    "    x_a = x_mean.sel(season=season_prof).to_pandas()[x_vars]\n",
    "    S_a = x_cov.sel(season=season_prof).to_pandas().loc[x_vars, x_vars]\n",
    "\n",
    "# Define dictionary of parameters for the forward model:\n",
    "\n",
    "    forwardKwArgs = dict(\n",
    "        myProfiles = myProfiles, \n",
    "        ssmiRttov = ssmiRttov\n",
    "    )\n",
    "\n",
    "# Call the forward model (i.e. creating synthetic obs.)\n",
    "\n",
    "    y_obs = forwardRT(x_truth, **forwardKwArgs)\n",
    "    y_obs = pn.Series(y_obs, index=y_vars)\n",
    "    assert np.all(np.isfinite(y_obs))\n",
    "\n",
    "# Create optimalEstimation instance:\n",
    "\n",
    "    oe_ref = pyOE.optimalEstimation(\n",
    "        x_vars, # state variable names\n",
    "        x_a,  # a priori\n",
    "        S_a, # a priori uncertainty\n",
    "        y_vars,  # measurement variable names\n",
    "        y_obs, # observations\n",
    "        S_y, # observation uncertainty\n",
    "        forwardRT, # forward Operator\n",
    "        forwardKwArgs=forwardKwArgs, # additonal function arguments\n",
    "        x_truth=x_truth, # true profile\n",
    "    )\n",
    "\n",
    "    oe_ref.doRetrieval()\n",
    "\n",
    "    _, _, w_op[ind] = supporting_routines_m.splitX(oe_ref.x_op)\n",
    "    _, _, w_op_err[ind] = supporting_routines_m.splitX(oe_ref.x_op_err)\n",
    "    #_, _, w_a[ind] = supporting_routines_m.splitX(oe_ref.x_a)\n",
    "    #_, _, w_a_err[ind] = supporting_routines_m.splitX(oe_ref.x_a_err)\n",
    "    _, _, w_truth[ind] = supporting_routines_m.splitX(oe_ref.x_truth)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(w_truth, w_op))\n",
    "    mae = median_absolut_error(w_truth, w_op)\n",
    "    \n",
    "    #chiSquareTest[ind] = oe_ref.chiSquareTest(significance=0.05)\n",
    "    #for x in chiSquareTest[0]: print (x)\n",
    "    #linearity, trueLinearityChi2, trueLinearityChi2Crit = oe_ref.linearityTest(significance=0.05)\n",
    "    #boole = np.bool(trueLinearityChi2 < trueLinearityChi2Crit)\n",
    "    #linearityTest[ind] = boole\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All units below are m/s:')\n",
    "print('Optimal wind speed:')\n",
    "print(w_op)\n",
    "print('Optimal wind speed error:')\n",
    "print(w_op_err)\n",
    "print('A-priori wind speed:')\n",
    "print(w_a)\n",
    "print('A-priori wind speed error:')\n",
    "print(w_a_err)\n",
    "print('True wind speed:')\n",
    "print(w_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting graph \n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "plt.scatter(w_truth, w_op, \n",
    "             marker ='o', color='orange', label='D') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rmse = np.sqrt(mean_squared_error(w_truth, w_op))\n",
    "\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_op, q_op, w_op = supporting_routines_m.splitX(oe_ref.x_op)\n",
    "t_op_err, q_op_err, w_op_err = supporting_routines_m.splitX(oe_ref.x_op_err)\n",
    "t_a, q_a, w_a = supporting_routines_m.splitX(oe_ref.x_a)\n",
    "t_a_err, q_a_err, w_a_err = supporting_routines_m.splitX(oe_ref.x_a_err)\n",
    "t_truth, q_truth, w_truth = supporting_routines_m.splitX(oe_ref.x_truth)\n",
    "print('All units below are m/s:')\n",
    "print('Optimal wind speed:')\n",
    "print(w_op)\n",
    "print('Optimal wind speed error:')\n",
    "print(w_op_err)\n",
    "print('A-priori wind speed:')\n",
    "print(w_a)\n",
    "print('A-priori wind speed error:')\n",
    "print(w_a_err)\n",
    "print('True wind speed:')\n",
    "print(w_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = supporting_routines_m.plotMwrResultsX(\n",
    "    oe_ref,\n",
    "    h=pressure.loc[season],\n",
    "    hlabel='Pressure [hPa]',\n",
    "    title='Reference run')\n",
    "plt.savefig('TQ_with_1Sigma_1', dpi=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map related plots (Cartopy)\n",
    "\n",
    "#lat2 = [-53.06520080566406,-41.81959915161133, -31.13629913330078,-47.16130065917969,-36.618499755859375]\n",
    "#long2 = [105.07499694824219,12.777799606323242,40.15999984741211,102.4000015258789,134.5]\n",
    "\n",
    "lat2 = profiles.lat.values\n",
    "long2 = profiles.long.values\n",
    "\n",
    "plt.figure(figsize=(13,6.2))\n",
    "    \n",
    "ax = plt.subplot(111, projection=ccrs.PlateCarree())\n",
    "\n",
    "ax.scatter(long,\\\n",
    "                   lat,marker='.',color='red')\n",
    "ax.scatter(long2,\\\n",
    "                   lat2,marker='o',color='blue')\n",
    "ax.coastlines();\n",
    "\n",
    "ax.grid(True)\n",
    "\n",
    "ax.set_xlabel('Longitude [deg]')\n",
    "ax.set_ylabel('Latitude [deg]')\n",
    "\n",
    "ax.stock_img();\n",
    "\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), linewidth=2, color='black', alpha=0.5, linestyle='--', draw_labels=True)\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_left = False\n",
    "gl.ylabels_right=True\n",
    "gl.xlines = True\n",
    "gl.xlocator = mticker.FixedLocator([-180, -120, -60, 0, 60, 120, 180])\n",
    "gl.ylocator = mticker.FixedLocator([-60, -30, 0, 30, 60])\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "\n",
    "plt.savefig('Sampling_map.png', dpi=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create covariance matrix as a pandas dataframe:\n",
    "S_a = x_cov.sel(season='MAM').to_pandas()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(9, 6))\n",
    "sns.heatmap(S_a.iloc[2::2, 2::2], ax=ax, cbar_kws={'label':'Covariance [K$^2$]'})\n",
    "ax.set_title('$\\mathbb{S}_{a}$ Temperature')\n",
    "plt.savefig('SaTemp_LatLong_0_60_-60_0.png', dpi=450)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(9, 6))\n",
    "sns.heatmap(S_a.iloc[1::2, 1::2], ax=ax, cbar_kws={'label':'Covariance [log$_{10}$(g/kg)$^2$]'})\n",
    "ax.set_title('$\\mathbb{S}_{a}$ Humidity')\n",
    "plt.savefig('SaHum_LatLong_0_60_-60_0.png', dpi=450)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(9, 6))\n",
    "sns.heatmap(S_a.iloc[::10, ::10], ax=ax, cbar_kws={'label':'Covariance [log$_{10}$(g/kg)$^2$]'})\n",
    "ax.set_title('$\\mathbb{S}_{a}$ Wind')\n",
    "plt.savefig('SaHum_LatLong_0_60_-60_0.png', dpi=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtime = datetime(year=1990,month=10,day=2,hour=18,minute=30,second=30)\n",
    "type(dtime.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in ['Humidity', 'Temperature']:\n",
    "    for h in range(0, 137, 20):\n",
    "        fig, (ax, ax1) = plt.subplots(ncols=2)\n",
    "        plt.suptitle('%s at level %i' % (var,h))\n",
    "        (osm, osr), (slope, intercept, r) = stats.probplot(\n",
    "            prior_all[var].isel(height=h).values[lat_long_mask],\n",
    "            dist=\"norm\",\n",
    "            plot=ax,\n",
    "            fit=True,\n",
    "            rvalue=False)\n",
    "        ax.text(\n",
    "            0.05,\n",
    "            0.95,\n",
    "            '%s) %s, R$^2$=%.3g' % ('a', var, r**2),\n",
    "            horizontalalignment='left',\n",
    "            verticalalignment='top',\n",
    "            transform=ax.transAxes)\n",
    "\n",
    "        (osm, osr), (slope, intercept, r) = stats.probplot(\n",
    "            np.log10(prior_all[var].isel(height=h).values[lat_long_mask]),\n",
    "            dist=\"norm\",\n",
    "            plot=ax1,\n",
    "            fit=True,\n",
    "            rvalue=False)\n",
    "        ax1.text(\n",
    "            0.05,\n",
    "            0.95,\n",
    "            '%s) %s, R$^2$=%.3g' % ('b', 'log10(%s)'%var, r**2),\n",
    "            horizontalalignment='left',\n",
    "            verticalalignment='top',\n",
    "            transform=ax1.transAxes)\n",
    "        fig.tight_layout()\n",
    "        plt.savefig('Prob_plot'+var+str(h)+'.png', dpi=450) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\n",
    "for season in ['all'] + seasons:\n",
    "    t, q, w = supporting_routines_m.splitX(x_mean.sel(season=season).to_pandas())\n",
    "    ax1.plot(t, t.index, label=season)\n",
    "    ax2.plot(q, q.index, label=season)\n",
    "\n",
    "ax2.legend()\n",
    "ax1.set_xlabel('Temperature [K]')\n",
    "ax2.set_xlabel('Specific Humidity [log$_{10}$(g/kg)]')\n",
    "ax1.set_ylabel('Height [m]')\n",
    "\n",
    "ax1.grid(True)\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.savefig('LatLong-70_-20_0_180.png', dpi=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\n",
    "for season in ['all'] + seasons:\n",
    "    # mean and (cov)-variances\n",
    "    x_a = x_mean.sel(season=season).to_pandas()[x_vars]\n",
    "    S_a = x_cov.sel(season=season).to_pandas().loc[x_vars, x_vars]\n",
    "    \n",
    "    xa_t, xa_q = supporting_routines.splitTQ(x_a)\n",
    "    # Errors:\n",
    "    xa_err = np.sqrt(pn.Series(np.diag(S_a), index=list(x_vars)))\n",
    "    xa_err_t, xa_err_q = supporting_routines.splitTQ(xa_err)\n",
    "    \n",
    "    \n",
    "    ax1.plot(xa_t, xa_t.index,label=season) #, color='C1', label='Prior')\n",
    "    ax1.fill_betweenx(xa_t.index, xa_t+xa_err_t, xa_t-xa_err_t,\n",
    "                          alpha=0.2)\n",
    "                          #color='C1', alpha=0.2)\n",
    "    ax2.plot(xa_q, xa_q.index,label=season) #, color='C0', label='Prior')\n",
    "    ax2.fill_betweenx(xa_q.index, xa_q+xa_err_q, xa_q-xa_err_q,\n",
    "                          alpha=0.2)\n",
    "                          #color='C0', alpha=0.2)\n",
    "    #t, q = supporting_routines.splitTQ(x_mean.sel(season=season).to_pandas())\n",
    "    #ax1.plot(t, t.index, label=season)\n",
    "    #ax2.plot(q, q.index, label=season)\n",
    "\n",
    "ax2.legend()\n",
    "ax1.set_xlabel('Temperature [K]')\n",
    "ax2.set_xlabel('Specific Humidity [log$_{10}$(g/kg)]')\n",
    "ax1.set_ylabel('Height [m]')\n",
    "\n",
    "ax1.grid(True)\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.savefig('LatLong_-70_-20_0_180_meanErr.png', dpi=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in ['W10']:\n",
    "    fig, (ax, ax1) = plt.subplots(ncols=2)\n",
    "    plt.suptitle('%s on surface' % (var))\n",
    "    (osm, osr), (slope, intercept, r) = stats.probplot(\n",
    "        prior_all[var].values[lat_long_mask],\n",
    "        dist=\"norm\",\n",
    "        plot=ax,\n",
    "        fit=True,\n",
    "        rvalue=False)\n",
    "    ax.text(\n",
    "        0.05,\n",
    "        0.95,\n",
    "        '%s) %s, R$^2$=%.3g' % ('a', var, r**2),\n",
    "        horizontalalignment='left',\n",
    "        verticalalignment='top',\n",
    "        transform=ax.transAxes)\n",
    "\n",
    "    (osm, osr), (slope, intercept, r) = stats.probplot(\n",
    "        np.log10(prior_all[var].values[lat_long_mask]),\n",
    "        dist=\"norm\",\n",
    "        plot=ax1,\n",
    "        fit=True,\n",
    "        rvalue=False)\n",
    "    ax1.text(\n",
    "        0.05,\n",
    "        0.95,\n",
    "        '%s) %s, R$^2$=%.3g' % ('b', 'log10(%s)'%var, r**2),\n",
    "        horizontalalignment='left',\n",
    "        verticalalignment='top',\n",
    "        transform=ax1.transAxes)\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "# Use only one feature\n",
    "diabetes_X = diabetes_X[:, np.newaxis, 2]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes_y[:-20]\n",
    "diabetes_y_test = diabetes_y[-20:]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "diabetes_y_pred = regr.predict(diabetes_X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(diabetes_y_test, diabetes_y_pred))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
    "plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_X_train.shape\n",
    "diabetes_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w_truth2.shape) \n",
    "print(w_op2.shape)\n",
    "#w = np.reshape(w_truth2,(len(w_truth2),1))\n",
    "w = np.copy(w_truth2)\n",
    "w.reshape(-1,1)\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\n",
    "\n",
    "t, q, w = supporting_routines_m.splitX(oe_ref.x_op)\n",
    "ax1.plot(t, t.index, label='DJF op')\n",
    "ax2.plot(q, q.index, label='DJF op')\n",
    "\n",
    "t, q, w = supporting_routines_m.splitX(oe_ref.x_a)\n",
    "ax1.plot(t, t.index, label='DJF a-priori')\n",
    "ax2.plot(q, q.index, label='DJF a-priori')\n",
    "\n",
    "t, q, w = supporting_routines_m.splitX(oe_ref.x_truth)\n",
    "ax1.plot(t, t.index, label='DJF truth')\n",
    "ax2.plot(q, q.index, label='DJF truth')\n",
    "\n",
    "ax2.legend()\n",
    "ax1.set_xlabel('Temperature [K]')\n",
    "ax2.set_xlabel('Specific Humidity [log$_{10}$(g/kg)]')\n",
    "ax1.set_ylabel('Height [m]')\n",
    "\n",
    "ax1.grid(True)\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.savefig('TQ_true_vs_other_1', dpi=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a simple plot for winds \n",
    "\n",
    "x =[1, 2, 3, 4, 5] \n",
    "x_season =[1, 2, 3, 4] \n",
    "# A-priori:\n",
    "y_a =[8.73, 9.09, 9.09, 8.85, 9.58]\n",
    "y_a_season =[8.73, 9.09, 8.85, 9.58]\n",
    "# Optimal:\n",
    "y_op1 = [12.97, 6.07, 17.72, 12.51, 10.81]\n",
    "y_op2 = [12.16, 6.03, 16.09, 12.04, 10.25]\n",
    "y_op3 = [12.76, 6.68, 16.60, 11.74, 11.42]\n",
    "y_op4 = [9.77, 5.77, 14.79, 10.79, 8.79]\n",
    "\n",
    "# True:\n",
    "y_true1 = [13.69, 6.02, 20.59, 12.90, 11.72]\n",
    " \n",
    "# creating error \n",
    "y_a_error = [4.12, 4.90, 4.90, 3.79, 4.31]\n",
    "y_a_error_season = [4.12, 4.90, 3.79, 4.31]\n",
    "y_op_error1 = [1.67, 1.73, 2.81, 1.82, 1.78]\n",
    "y_op_error2 = [2.37, 2.29, 3.48, 2.39, 2.39]\n",
    "y_op_error3 = [1.82, 1.93, 3.05, 1.95, 1.95]\n",
    "y_op_error4 = [3.72, 3.85, 3.93, 3.34, 3.76]\n",
    "\n",
    "# ploting graph \n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "plt.errorbar(x_season, y_a_season, \n",
    "             yerr = y_a_error_season, \n",
    "             fmt ='o', capsize=8, color='orange', label='A-priori NS wind speed, $\\mu \\pm \\sigma$') \n",
    "plt.xticks(x_season, ('SON', 'DJF', 'MAM', 'JJA'))\n",
    "\n",
    "plt.ylim(0,15)\n",
    "plt.minorticks_off()\n",
    "\n",
    "ax.legend()\n",
    "ax.set_ylabel('Near Surface Wind Speed [m/s]')\n",
    "ax.set_xlabel('Seasons')\n",
    "ax.grid(True)\n",
    "plt.savefig('a-priori_wind_bar1', dpi=450)\n",
    "\n",
    "# Comparison 4 tested cases:\n",
    "# case 1 ////////////////////\n",
    "# ploting graph \n",
    "fig, ax = plt.subplots(1)\n",
    "plt.scatter(x, y_true1, marker='s', color='green', alpha = 0.3, label='True') \n",
    "plt.errorbar(x, y_a, \n",
    "             yerr = y_a_error, \n",
    "             fmt ='o', capsize=8 , color='orange', label='A-priori') \n",
    "plt.errorbar(x, y_op1, \n",
    "             yerr = y_op_error1, \n",
    "             fmt ='o', capsize=5, fillstyle='left', color='blue', alpha = 0.5, label='Optimal') \n",
    "plt.xticks(x, ('loc1, SON', 'loc2, DJF', 'loc3, DJF', 'loc4, MAM', 'loc5, JJA'))\n",
    "\n",
    "plt.ylim(0,21)\n",
    "#plt.xlim(0,7)\n",
    "plt.minorticks_off()\n",
    "\n",
    "ax.legend()\n",
    "ax.set_ylabel('Near Surface Wind Speed [m/s]')\n",
    "ax.set_xlabel('Locations for test')\n",
    "ax.grid(True)\n",
    "plt.savefig('all_wind_bar1', dpi=450)\n",
    "\n",
    "# case 2 //////////////////////////\n",
    "# ploting graph \n",
    "fig, ax = plt.subplots(1)\n",
    "plt.scatter(x, y_true1, marker='s', color='green', alpha = 0.3, label='True') \n",
    "plt.errorbar(x, y_a, \n",
    "             yerr = y_a_error, \n",
    "             fmt ='o', capsize=8 , color='orange', label='A-priori') \n",
    "plt.errorbar(x, y_op2, \n",
    "             yerr = y_op_error2, \n",
    "             fmt ='o', capsize=5, fillstyle='left', color='blue', alpha = 0.5, label='Optimal') \n",
    "plt.xticks(x, ('loc1, SON', 'loc2, DJF', 'loc3, DJF', 'loc4, MAM', 'loc5, JJA'))\n",
    "\n",
    "plt.ylim(0,21)\n",
    "#plt.xlim(0,7)\n",
    "plt.minorticks_off()\n",
    "\n",
    "ax.legend()\n",
    "ax.set_ylabel('Near Surface Wind Speed [m/s]')\n",
    "ax.set_xlabel('Locations for test')\n",
    "ax.grid(True)\n",
    "plt.savefig('all_wind_bar2', dpi=450)\n",
    "\n",
    "# case 3 ///////////////////////\n",
    "# ploting graph \n",
    "fig, ax = plt.subplots(1)\n",
    "plt.scatter(x, y_true1, marker='s', color='green', alpha = 0.3, label='True') \n",
    "plt.errorbar(x, y_a, \n",
    "             yerr = y_a_error, \n",
    "             fmt ='o', capsize=8 , color='orange', label='A-priori') \n",
    "plt.errorbar(x, y_op3, \n",
    "             yerr = y_op_error3, \n",
    "             fmt ='o', capsize=5, fillstyle='left', color='blue', alpha = 0.5, label='Optimal') \n",
    "plt.xticks(x, ('loc1, SON', 'loc2, DJF', 'loc3, DJF', 'loc4, MAM', 'loc5, JJA'))\n",
    "\n",
    "plt.ylim(0,21)\n",
    "#plt.xlim(0,7)\n",
    "plt.minorticks_off()\n",
    "\n",
    "ax.legend()\n",
    "ax.set_ylabel('Near Surface Wind Speed [m/s]')\n",
    "ax.set_xlabel('Locations for test')\n",
    "ax.grid(True)\n",
    "plt.savefig('all_wind_bar3', dpi=450)\n",
    "\n",
    "# case 4 ///////////////////////////\n",
    "# ploting graph \n",
    "fig, ax = plt.subplots(1)\n",
    "plt.scatter(x, y_true1, marker='s', color='green', alpha = 0.3, label='True') \n",
    "plt.errorbar(x, y_a, \n",
    "             yerr = y_a_error, \n",
    "             fmt ='o', capsize=8 , color='orange', label='A-priori') \n",
    "plt.errorbar(x, y_op4, \n",
    "             yerr = y_op_error4, \n",
    "             fmt ='o', capsize=5, fillstyle='left', color='blue', alpha = 0.5, label='Optimal') \n",
    "plt.xticks(x, ('loc1, SON', 'loc2, DJF', 'loc3, DJF', 'loc4, MAM', 'loc5, JJA'))\n",
    "\n",
    "plt.ylim(0,21)\n",
    "#plt.xlim(0,7)\n",
    "plt.minorticks_off()\n",
    "\n",
    "ax.legend()\n",
    "ax.set_ylabel('Near Surface Wind Speed [m/s]')\n",
    "ax.set_xlabel('Locations for test')\n",
    "ax.grid(True)\n",
    "plt.savefig('all_wind_bar4', dpi=450)\n",
    "\n",
    "# all 4 cases: //////////////////////\n",
    "# ploting graph \n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\n",
    "#plt.scatter(x, y_true1, marker='s', color='green', alpha = 0.3, label='True') \n",
    "\n",
    "ax1.plot(x, np.absolute(np.array(y_true1)-np.array(y_op1)), marker ='o', \n",
    "            color='blue', alpha = 0.5, label='All ch') \n",
    "ax2.plot(x, y_op_error1, marker ='s', \n",
    "            color='blue', alpha = 0.5, label='All ch') \n",
    "ax1.plot(x, np.absolute(np.array(y_true1)-np.array(y_op2)), marker ='o', \n",
    "            color='red', alpha = 0.5, label='All ch - h_var') \n",
    "ax2.plot(x, y_op_error2, marker ='s', \n",
    "            color='red', alpha = 0.5, label='All ch - h_var') \n",
    "ax1.plot(x, np.absolute(np.array(y_true1)-np.array(y_op3)), marker ='o', \n",
    "            color='green', alpha = 0.5, label='Window ch') \n",
    "ax2.plot(x, y_op_error3, marker ='s', \n",
    "            color='green', alpha = 0.5, label='Window ch') \n",
    "ax1.plot(x, np.absolute(np.array(y_true1)-np.array(y_op4)), marker ='o', \n",
    "            color='orange', alpha = 0.5, label='Absorp ch') \n",
    "ax2.plot(x, y_op_error4, marker ='s', \n",
    "            color='orange', alpha = 0.5, label='Absorp ch') \n",
    "\n",
    "ax1.set_xticks(x)\n",
    "ax2.set_xticks(x)\n",
    "ax1.set_xticklabels(['loc1, SON', 'loc2, DJF', 'loc3, DJF', 'loc4, MAM', 'loc5, JJA'], rotation=30)\n",
    "ax2.set_xticklabels(['loc1, SON', 'loc2, DJF', 'loc3, DJF', 'loc4, MAM', 'loc5, JJA'], rotation=30)\n",
    "\n",
    "ax1.grid(True)\n",
    "ax2.grid(True)\n",
    "\n",
    "\n",
    "ax1.set_title('abs(True-Optimal)')\n",
    "ax2.set_title('Uncertainty (1 $\\sigma$)')\n",
    "\n",
    "ax2.legend()\n",
    "\n",
    "ax1.set_ylabel('Error in Wind Speed [m/s]')\n",
    "#ax.set_xlabel('Locations for test')\n",
    "#ax.grid(True)\n",
    "plt.savefig('all_wind_errors', dpi=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
