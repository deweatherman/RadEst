{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import datetime \n",
    "import time\n",
    "from datetime import datetime \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#import sklearn\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error,r2_score\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor, HuberRegressor\n",
    "\n",
    "\n",
    "import pyOptimalEstimation as pyOE\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "from cmocean import cm as cmo\n",
    "\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('support')\n",
    "\n",
    "import supporting_routines_m \n",
    "\n",
    "import os\n",
    "\n",
    "rttov_installdir = '/home/mario/myLibs/rrtov13/rttov130'\n",
    "\n",
    "sys.path.append(rttov_installdir+'/wrapper')\n",
    "import pyrttov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aprio_dir = '/home/mario/Data/RadEst_crossVal_data/crossVal_aprioriData/'\n",
    "prior_all = supporting_routines_m.concatDiverse(aprio_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of levels for the profiles in the priors\n",
    "\n",
    "nlevels = len(prior_all['height'])\n",
    "nprofiles = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channels corrispondence:\n",
    "\n",
    "# from: D. B. Kunkee et al, \"Design and Evaluation of the First \n",
    "# Special Sensor Microwave Imager/Sounder\", IEEE Trans. Geosc. Rem. Sens. \n",
    "# Vol. 46, NO. 4, April 2008.\n",
    "# Table 1\n",
    "# Ch. 1 - 50.3 GHz Hpol (check note on pol at source for this channel) \n",
    "# Ch. 12 - 19.35 GHz Hpol\n",
    "# Ch. 13 - 19.35 GHz Vpol\n",
    "# Ch. 14 - 22.235 GHz Vpol\n",
    "# Ch. 15 - 37 GHz Hpol\n",
    "# Ch. 16 - 37 GHz Vpol\n",
    "\n",
    "ssmiRttov = pyrttov.Rttov()\n",
    "\n",
    "# SSMIS:\n",
    "nchan_ssmi = 14\n",
    "chan_list_ssmi = (1,2,3,4,5,6,7,12,13,14,15,16,23,24) #(1,12,13,14,15,16) #  #\n",
    "ssmiRttov.FileCoef = '{}/{}'.format(rttov_installdir,\n",
    "                                    \"rtcoef_rttov13/rttov7pred54L/rtcoef_dmsp_18_ssmis.dat\")\n",
    "\n",
    "# WindSat:\n",
    "#nchan_ssmi = 16\n",
    "#chan_list_ssmi = (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16) #(1,2,3,4,7,8,11,12,13,14) #(1,12,13,14,15,16) #  #\n",
    "#ssmiRttov.FileCoef = '{}/{}'.format(rttov_installdir,\n",
    "#                                    \"rtcoef_rttov12/rttov7pred54L/rtcoef_coriolis_1_windsat.dat\")\n",
    "\n",
    "ssmiRttov.Options.AddInterp = True\n",
    "ssmiRttov.Options.CO2Data = False\n",
    "ssmiRttov.Options.VerboseWrapper = True\n",
    "ssmiRttov.Options.DoCheckinput = False\n",
    "ssmiRttov.Options.UseQ2m = True\n",
    "ssmiRttov.Options.ApplyRegLimits = True\n",
    "ssmiRttov.Options.Verbose = False\n",
    "ssmiRttov.Options.FastemVersion = 6 \n",
    "\n",
    "# Load the instruments: for HIRS and MHS do not supply a channel list and\n",
    "# so read all channels\n",
    "try:\n",
    "    ssmiRttov.loadInst(chan_list_ssmi)\n",
    "except pyrttov.RttovError as e:\n",
    "    sys.stderr.write(\"Error loading instrument(s): {!s}\".format(e))\n",
    "    sys.exit(1)\n",
    "\n",
    "# Load Atlases: (if any)    \n",
    "ssmiRttov.SurfEmisRefl = np.zeros((4,nprofiles,nchan_ssmi), dtype=np.float64) # RTTOVv12 used (2,nprof,nchan)\n",
    "\n",
    "# Definition of the observation variables\n",
    "y_vars = np.array(chan_list_ssmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY FOR MULTIPLE PROFILES CALL TESTING\n",
    "\n",
    "ssmiRttovM = pyrttov.Rttov()\n",
    "\n",
    "# SSMIS:\n",
    "nchan_ssmiM = 14\n",
    "chan_list_ssmiM = (1,2,3,4,5,6,7,12,13,14,15,16,23,24) #(1,12,13,14,15,16) #  #\n",
    "ssmiRttovM.FileCoef = '{}/{}'.format(rttov_installdir,\n",
    "                                    \"rtcoef_rttov13/rttov7pred54L/rtcoef_dmsp_18_ssmis.dat\")\n",
    "\n",
    "ssmiRttovM.Options.AddInterp = True\n",
    "ssmiRttovM.Options.CO2Data = False\n",
    "ssmiRttovM.Options.VerboseWrapper = True\n",
    "ssmiRttovM.Options.DoCheckinput = False\n",
    "ssmiRttovM.Options.UseQ2m = True\n",
    "ssmiRttovM.Options.ApplyRegLimits = True\n",
    "ssmiRttovM.Options.Verbose = False\n",
    "ssmiRttovM.Options.FastemVersion = 6 \n",
    "\n",
    "# Load the instruments: for HIRS and MHS do not supply a channel list and\n",
    "# so read all channels\n",
    "try:\n",
    "    ssmiRttovM.loadInst(chan_list_ssmiM)\n",
    "except pyrttov.RttovError as e:\n",
    "    sys.stderr.write(\"Error loading instrument(s): {!s}\".format(e))\n",
    "    sys.exit(1)\n",
    "\n",
    "# Load Atlases: (if any)    \n",
    "ssmiRttovM.SurfEmisRefl = np.zeros((4,279,nchan_ssmi), dtype=np.float64) # RTTOVv12 used (2,nprof,nchan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Values for the noise are obtained from HOAPS R matrix (Table 2, p20, HOAPS 4.0 ATBD)\n",
    "\n",
    "#y_noise = pd.Series(\n",
    "#    [\n",
    "#        2.44948974, 1.54919338, 1.341640787, 1.341640787, 1.949358869, 1.341640787\n",
    "#    ],\n",
    "#    index=y_vars\n",
    "#)\n",
    "\n",
    "#S_y = pd.DataFrame(\n",
    "#    np.diag(y_noise.values**2),\n",
    "#    index=y_vars,\n",
    "#    columns=y_vars,\n",
    "#)\n",
    "#\n",
    "\n",
    "# JUST FOR TESTING THE EFFECT ON SLOPE VIAS IN CROSS-VALIDATION (DON'T USE IN REAL APPLICATION)\n",
    "# Channels 1-7, 12-16, 23, 24 (MODIFIED values from Deblonde-English 2003) (sigma or std)\n",
    "#y_noise = pd.Series(\n",
    "#    [\n",
    "#        1.3, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 2.0, 1.07, 1.24, 2.5, 1.14, 0.46, 0.47\n",
    "#   ],\n",
    "#    index=y_vars\n",
    "#)\n",
    "# JUST FOR TESTING THE EFFECT ON SLOPE VIAS IN CROSS-VALIDATION (DON'T USE IN REAL APPLICATION)\n",
    "\n",
    "\n",
    "# FOR TEST USING NEDT VALUES FROM SSMIS ONLY (From Kunkee 2008)\n",
    "# Channels 1-7, 12-16, 23, 24 (values in K)\n",
    "#y_noise = pd.Series(\n",
    "#    [\n",
    "#        0.34, 0.32, 0.33, 0.33, 0.34, 0.41, 0.40, 0.33, 0.31, 0.43, 0.25, 0.20, 0.8, 0.9 \n",
    "#   ],\n",
    "#    index=y_vars\n",
    "#)\n",
    "# FOR TEST USING NEDT VALUES FROM SSMIS ONLY (From Kunkee 2008)\n",
    "\n",
    "\n",
    "# Channels 1-7, 12-16, 23, 24 (values from Deblonde-English 2003) (sigma or std)\n",
    "y_noise = pd.Series(\n",
    "    [\n",
    "        1.5, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 2.4, 1.27, 1.44, 3.0, 1.34, 0.46, 0.47\n",
    "   ],\n",
    "    index=y_vars\n",
    ")\n",
    "\n",
    "# Channels 1-7, 13,14,16, 23, 24 (values from Deblonde-English 2003) (sigma or std)\n",
    "#y_noise = pd.Series(\n",
    "#    [\n",
    "#        1.5, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 1.27, 1.44, 1.34, 0.46, 0.47\n",
    "#    ],\n",
    "#    index=y_vars\n",
    "#)\n",
    "\n",
    "# Channels 1,12-16 (values from Deblonde-English 2003) (sigma or std)\n",
    "#y_noise = pd.Series(\n",
    "#    [\n",
    "#        1.5, 2.4, 1.27, 1.44, 3.0, 1.34\n",
    "#    ],\n",
    "#    index=y_vars\n",
    "#)\n",
    "\n",
    "# Channels 2-7, 23, 24 (values from Deblonde-English 2003) (sigma or std)\n",
    "#y_noise = pd.Series(\n",
    "#    [\n",
    "#        0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.46, 0.47\n",
    "#    ],\n",
    "#    index=y_vars\n",
    "#)\n",
    "\n",
    "\n",
    "# Channels 1-16 WindSat (from Table 2 in M. Bettenhausen et al, \n",
    "# \"A Nonlinear Optimization Algorithm for WindSat Wind Vector Retrievals\", \n",
    "# IEEE Trans. Geo. Rem. Sen., Vol 44, No. 3, March 2006):\n",
    "\n",
    "# Take \"Polarimetric\" channels away:\n",
    "#y_noise = pd.Series(\n",
    "#    [\n",
    "#        0.60, 0.78, 0.69, 0.99, 1.02, 2.02, 1.38,\n",
    "#        2.51, 1.76, 3.65\n",
    "#    ],\n",
    "#    index=y_vars\n",
    "#)\n",
    "\n",
    "#y_noise = pd.Series(\n",
    "#    [\n",
    "#        0.60, 0.78, 0.69, 0.99, 0.26, 0.09, 1.02, 2.02, 0.28, 0.12, 1.38,\n",
    "#        2.51, 1.76, 3.65, 0.25, 0.09\n",
    "#    ],\n",
    "#    index=y_vars\n",
    "#)\n",
    "\n",
    "# Variance values > std**2\n",
    "S_y = pd.DataFrame(\n",
    "    np.diag(y_noise.values**2),\n",
    "    index=y_vars,\n",
    "    columns=y_vars,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the indices of the \"local prior\":\n",
    "# we will call local prior to the prior built\n",
    "# using a geographical area \"nearby\" the observation\n",
    "# location (i.e. a bounding box around the observation location). \n",
    "# All the atmospheric states within such a box \n",
    "# Define our a-priori knowledge (in the spatial domain)\n",
    "\n",
    "lat_min = -90.0\n",
    "lat_max = -40.0\n",
    "long_min = -180.0\n",
    "long_max = 180.0\n",
    "\n",
    "\n",
    "lat_long_mask = np.array([(prior_all['lat'].values[:]>lat_min)&(prior_all['lat'].values[:]<lat_max)&\n",
    "                 ((prior_all['long'].values[:]>long_min)&(prior_all['long'].values[:]<long_max))])\n",
    "lat_long_mask=lat_long_mask.reshape(-1)\n",
    "#lat_long_mask = ~lat_long_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a time index for the local prior:\n",
    "times1 = prior_all['Time'].values[lat_long_mask]\n",
    "\n",
    "time_index = np.zeros(len(times1),dtype='datetime64[s]')\n",
    "for i in range(len(times1)):\n",
    "    time_index[i] = supporting_routines_m.timestamp2datetime(times1[i])\n",
    "print(len(times1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lat, long vectors for auxiliary plots e.g. cartopy\n",
    "\n",
    "lat = prior_all['lat'].values[lat_long_mask]\n",
    "long = prior_all['long'].values[lat_long_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a \"local\" prior: Subset of \"prior_all\" \n",
    "# that contains only the selected lat,long area.\n",
    "\n",
    "prior_local = supporting_routines_m.maskPrior(prior_all, time_index, lat_long_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the humidity profiles to a logarithmic scale\n",
    "# in order to improve their normality (see probability plots)\n",
    "\n",
    "# IMPORTANT NOTE:\n",
    "# RTTOV ACCEPTS ONLY kg / kg (LINEAR SCALE)\n",
    "# THERE IS A LOG2LIN CONVERSION IN THE DEFINITION\n",
    "# OF THE FORWARD OPERATOR; BUT INSIDE THE OPTIMAL\n",
    "# ESTIMATION, THE HUMIDITY IS IN LOG SCALE\n",
    "\n",
    "prior_local['Humidity'] = np.log10(prior_local['Humidity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexTotal = np.arange(len(prior_local.time)) # all time indices in prior_local [0,1,...16000,..] \n",
    "\n",
    "# Create copy of the indices array\n",
    "kk = np.copy(indexTotal)\n",
    "\n",
    "# Shuffle the indices array randomly\n",
    "np.random.shuffle(kk)\n",
    "\n",
    "# Split the array in K folds (for K-fold cross validation)\n",
    "K = 10\n",
    "hh = np.array_split(kk,K)\n",
    "\n",
    "rmse = 0.0\n",
    "mae = 0.0 #np.empty(0)\n",
    "r2 = 0.0 #np.empty(0)\n",
    "count = np.empty(0,dtype=int)\n",
    "wind_opt = np.empty(0)\n",
    "wind_true = np.empty(0)\n",
    "wind_opt_err = np.empty(0)\n",
    "\n",
    "KK = 0\n",
    "\n",
    "for indexTest in hh: \n",
    "    \n",
    "    KK += 1\n",
    "# How many \"situations\" do we want to test \n",
    "#(these will be split apart from the a-priori dataset).\n",
    "# Situation means a (Lat, Long, time) combination:\n",
    "# i.e. 1 Situation is one datapoint from the prior_local dataset\n",
    "    nTestSamples = len(indexTest) \n",
    "\n",
    "# The actual indices from prior_local  that will be used as testing points: \n",
    "# i.e. they are taken out of the a-priori data\n",
    "#indexTest = np.random.choice(indexTotal,nTestSamples) # This is used only if a Monte Carlo type of cross validation is done\n",
    "\n",
    "# The test indices are deleted from the a-priori (i.e. training) set\n",
    "    indexTrain = np.delete(indexTotal,indexTest)\n",
    "\n",
    "# Split available diverse datasets into:\n",
    "# - 5 profiles to generate synthetic data (profiles)\n",
    "# - Rest of the profiles to generate the prior \n",
    "# The 5 profiles for synthetic data are EXCLUDED from\n",
    "# the rest of the datasets (e.g. from the prior)\n",
    "\n",
    "    profiles = prior_local.isel(time=indexTest)\n",
    "    prior_local_1 = prior_local.isel(time=indexTrain)\n",
    "    \n",
    "    nLev = len(prior_local_1.height)\n",
    "    # Splitting the priors per season:\n",
    "    priors, pressure, seasons, months, h_season = supporting_routines_m.priors2seasons(prior_local_1) \n",
    "    # Converting priors per season to pandas dataframes:\n",
    "    #prior_xa, prior_wind = supporting_routines_m.priors2pandas(priors, \n",
    "    #                                                            wind_components = True, h_season = h_season)\n",
    "    \n",
    "    flavor = 2 # check \"priors2Pandas\"\n",
    "    prior_xa, prior_b = supporting_routines_m.priors2Pandas(priors, \n",
    "                                                                flavor = flavor, h_season = h_season)    \n",
    "    x_cov, x_mean = supporting_routines_m.meanCov(prior_xa, seasons)\n",
    "\n",
    "# Definition of the state variables (names of the variables)\n",
    "    x_vars = x_mean.state.values\n",
    "\n",
    "# Assert invertibility of the convariance matrices:\n",
    "    for season in x_cov.season:\n",
    "        assert np.linalg.matrix_rank(\n",
    "            x_cov.sel(season=season).to_pandas()) ==  x_cov.shape[-1]\n",
    "        \n",
    "# Create x_truths: Pandas version of the profiles array (Containing only state variables!)\n",
    "    x_truths = supporting_routines_m.createTrueState(profiles, flavor=flavor)\n",
    "# Gather parameters for RTTOV from a-priori knowledge\n",
    "    \n",
    "    #prior_b = supporting_routines_m.b_fromPrior(priors)\n",
    "    \n",
    "# FOR RTTOV PARAMETERS\n",
    "# We use pandas tooling (cov, mean) to compute the mean\n",
    "# and covariance per season:  \n",
    "    b_cov, b_mean = supporting_routines_m.meanCov(prior_b, seasons)\n",
    "    b_vars = b_mean.state.values\n",
    "\n",
    "# Assert invertibility of the convariance matrices:\n",
    "    for season in x_cov.season:\n",
    "        assert np.linalg.matrix_rank(\n",
    "            b_cov.sel(season=season).to_pandas()) ==  b_cov.shape[-1]   \n",
    "    \n",
    "    #w_op = np.zeros(len(indexTest))\n",
    "    #w_op_err = np.zeros(len(indexTest))\n",
    "    #w_a = np.zeros(len(indexTest))\n",
    "    #w_a_err = np.zeros(len(indexTest))\n",
    "    #w_truth = np.zeros(len(indexTest))\n",
    "    #chiSquareTest = np.array(len(indexTest), dtype=bool)\n",
    "    #linearityTest = np.array(len(indexTest), dtype=bool)\n",
    "    w_op2 = np.empty(0)\n",
    "    w_op_err2 = np.empty(0)\n",
    "    w_truth2 = np.empty(0)\n",
    "    u_op2 = np.empty(0)\n",
    "    u_op_err2 = np.empty(0)\n",
    "    u_truth2 = np.empty(0)\n",
    "    v_op2 = np.empty(0)\n",
    "    v_op_err2 = np.empty(0)\n",
    "    v_truth2 = np.empty(0)    \n",
    "    lat_local = np.empty(0)\n",
    "    long_local = np.empty(0)\n",
    "    lat_skip = np.empty(0)\n",
    "    long_skip = np.empty(0)\n",
    "    seasonal = np.empty(0,dtype=object)\n",
    "        \n",
    "    count_breaks = 0\n",
    "    count_nc = 0\n",
    "    for ind in np.arange(len(indexTest)):\n",
    "\n",
    "        prof = profiles.time.values[ind] \n",
    "        seasonIndex = int(np.where(np.isin(months,profiles['time.month'].values[ind]))[0])\n",
    "        season_prof = seasons[seasonIndex]\n",
    "\n",
    "# Profile used for generating synthetic observation:\n",
    "# Contains ONLY the to-be-retrieved parameters: \n",
    "# temperature, humidity, 10m surface windspeed\n",
    "        x_truth = x_truths.iloc[ind]\n",
    "\n",
    "        Pressure = pressure.loc[season_prof,:].values[:] \n",
    "\n",
    "# Other parameters needed for the radiative transfer model (RTTOV)\n",
    "        lat1 = np.float64(profiles.lat.values[ind])\n",
    "        long1 = np.float64(profiles.long.values[ind])\n",
    "        datetime_obs = prof\n",
    "        zenithAngle = 53.0\n",
    "        salinity = 35\n",
    "\n",
    "# Create instance of Profiles class; \n",
    "# it's a container of the input atmospheric state that RTTOV will simulate\n",
    "\n",
    "        myProfiles = pyrttov.Profiles(nprofiles, nlevels)\n",
    "\n",
    "# Initialize multiple profiles for using a single call to RTTOV\n",
    "# This is to be passed to the Jacobian function inside pyOpEst:\n",
    "# The Jacobian is needed per parameter (len(x_truth.index))\n",
    "        nprofiles_test = len(x_truth.index) # total number of parameters (x and b)\n",
    "        myProfilesM = pyrttov.Profiles(nprofiles_test, nlevels) #  #Testing!\n",
    "\n",
    "# forward_b_init fills \"myProfiles\" with the \"fixed\" parameters for the RTTOV simulation.\n",
    "# The forward model F(x,b), RTTOV in our case, has two \"parameters\": x and b\n",
    "# x is the state vector that is being retrieved (as such it is allowed to change during the retrieval)\n",
    "# b contains all other parameters that are fixed during the retrieval (everything else that is not being retrieved)\n",
    "\n",
    "        forward_b_init(Pressure, salinity, \n",
    "              lat1, long1, datetime_obs, zenithAngle, myProfiles)\n",
    "\n",
    "    \n",
    "        press2 = np.zeros((nlevels,nprofiles_test))\n",
    "        x_truth_aux_data = np.zeros((nprofiles_test,nprofiles_test), dtype=np.float64) \n",
    "        columns_xtruth = []\n",
    "        for jj in np.arange(nprofiles_test):\n",
    "            press2[:,jj] = pressure.loc[season_prof,:].to_numpy()\n",
    "            x_truth_aux_data[:,jj] = x_truth.to_numpy() \n",
    "            columns_xtruth.append('profile_'+str(jj))\n",
    "\n",
    "        x_truth_aux = pd.DataFrame(x_truth_aux_data,\n",
    "            columns=columns_xtruth, index=x_truth.index, dtype=np.float64)\n",
    "        #print(x_truth_aux.head())\n",
    "        \n",
    "# Initialize profile datastructure for use in Jacobian computation:        \n",
    "        forward_b_init(press2, salinity, \n",
    "              lat1, long1, datetime_obs, zenithAngle, myProfilesM)    \n",
    "        \n",
    "# Define a-priori information: mean and covariance matrix\n",
    "# for a given season (DJF, MAM, JJA, SON)\n",
    "\n",
    "        x_a = x_mean.sel(season=season_prof).to_pandas()[x_vars]\n",
    "        S_a = x_cov.sel(season=season_prof).to_pandas().loc[x_vars, x_vars]\n",
    "        \n",
    "        # Vector of parameters and its covariance:\n",
    "        b_p = b_mean.sel(season=season_prof).to_pandas()[b_vars]\n",
    "        S_b = b_cov.sel(season=season_prof).to_pandas().loc[b_vars, b_vars]\n",
    "            \n",
    "# Define dictionary of parameters for the forward model:\n",
    "\n",
    "        #forwardKwArgs = dict(\n",
    "        #    myProfiles_a = myProfiles, \n",
    "        #    ssmiRttov_a = ssmiRttov\n",
    "        #)\n",
    "        forwardKwArgs = {\"myProfiles_a\" : myProfiles, \n",
    "                         \"ssmiRttov_a\" : ssmiRttov}\n",
    "                \n",
    "# Test for multiple profiles   \n",
    "        #forwardKwArgsM = dict(\n",
    "        #    myProfiles_a = myProfilesM, \n",
    "        #    ssmiRttov_a = ssmiRttovM\n",
    "        #)  \n",
    "        forwardKwArgsM = {\"myProfiles_a\" : myProfilesM, \n",
    "                         \"ssmiRttov_a\" : ssmiRttovM}    \n",
    "       \n",
    "        \n",
    "# Call the forward model (i.e. creating synthetic obs.)\n",
    "\n",
    "        y_obs = forwardRT(x_truth, **forwardKwArgs)\n",
    "        y_obs = pd.Series(y_obs, index=y_vars)\n",
    "        assert np.all(np.isfinite(y_obs))\n",
    "        \n",
    "        #y_K = KRT(x_truth, **forwardKwArgs)  # only for testing runK model from RTTOV, experimental!\n",
    "\n",
    "        #print('y_obs done') \n",
    "# Create optimalEstimation instance:\n",
    "\n",
    "        oe_ref = pyOE.optimalEstimation( # oe_1 if windDisambiguation used\n",
    "            x_vars, # state variable names\n",
    "            x_a,  # a priori\n",
    "            S_a, # a priori uncertainty\n",
    "            y_vars,  # measurement variable names\n",
    "            y_obs, # observations\n",
    "            S_y, # observation uncertainty\n",
    "            forwardRT, # forward Operator\n",
    "            forwardKwArgs=forwardKwArgs, # additonal function arguments\n",
    "            forwardKwArgsM=forwardKwArgsM, # additonal function arguments for jacobian tests\n",
    "            x_truth=x_truth, # true profile\n",
    "            b_vars=b_vars,   # Parameter vector variable names\n",
    "            b_p=b_p,        # Parameter vector \n",
    "            S_b=S_b        # Parameters error covariance matrix \n",
    "        )\n",
    "\n",
    "        #oe_1.doRetrieval()\n",
    "        oe_ref.doRetrieval()\n",
    "        \n",
    "        #time.sleep(3600)\n",
    "        \n",
    "        if not oe_ref.converged :  # oe_1 if windDisambiguation used\n",
    "            count_nc += 1\n",
    "            print('NO CONVERGENCE points:')\n",
    "            print(count_nc)\n",
    "            lat_skip = np.append(lat_skip,lat1)\n",
    "            long_skip = np.append(long_skip,long1)\n",
    "            continue\n",
    "\n",
    "        #oe_ref = windDisambiguation(oe_1,forwardRT,forwardKwArgs)  \n",
    "        \n",
    "# Not Including S_b, b_p:            \n",
    "        #_, _, w_op1 = supporting_routines_m.splitX(oe_ref.x_op)\n",
    "        #_, _, w_op_err1 = supporting_routines_m.splitX(oe_ref.x_op_err)\n",
    "        ##_, _, w_a[ind] = supporting_routines_m.splitX(oe_ref.x_a)\n",
    "        ##_, _, w_a_err[ind] = supporting_routines_m.splitX(oe_ref.x_a_err)\n",
    "        #_, _, w_truth1 = supporting_routines_m.splitX(oe_ref.x_truth)\n",
    "        \n",
    "    # U & V:\n",
    "        #_, _, u_op1, v_op1 = supporting_routines_m.splitXUV(oe_ref.x_op)\n",
    "        #_, _, u_op_err1, v_op_err1 = supporting_routines_m.splitXUV(oe_ref.x_op_err)\n",
    "        ##_, _, u_a1, v_a1 = supporting_routines_m.splitXUV(oe_ref.x_a)\n",
    "        ##_, _, u_a_err1, v_a_err1 = supporting_routines_m.splitXUV(oe_ref.x_a)\n",
    "        #_, _, u_truth1, v_truth1 = supporting_routines_m.splitXUV(oe_ref.x_truth) \n",
    "        #u_op2 = np.append(u_op2,u_op1)\n",
    "        #u_op_err2 = np.append(u_op_err2,u_op_err1)\n",
    "        #u_truth2 = np.append(u_truth2,u_truth1)\n",
    "        ## V component\n",
    "        #v_op2 = np.append(v_op2,v_op1)\n",
    "        #v_op_err2 = np.append(v_op_err2,v_op_err1)\n",
    "        #v_truth2 = np.append(v_truth2,v_truth1)          \n",
    "        ## Compute magnitude using coordinates U and V\n",
    "        ## w_op1 = np.sqrt( u_op1**2 + v_op1**2 )\n",
    "        #w_op1, w_op_err1 = supporting_routines_m.UV2Wvar(oe_ref.S_op.loc['00010_nu','00010_nu'],\n",
    "        #                                          oe_ref.S_op.loc['00010_nv','00010_nv'],\n",
    "        #                                          oe_ref.S_op.loc['00010_nu','00010_nv'],\n",
    "        #                                          u_op1,v_op1)\n",
    "        #w_truth1 = np.sqrt( u_truth1**2 + v_truth1**2 )        \n",
    "        \n",
    "# Including S_b, b_p:\n",
    "       # _,_, w_op1,_,_,_,_ = supporting_routines_m.splitXW_all(oe_ref.x_op)\n",
    "       # _,_, w_op_err1,_,_,_,_ = supporting_routines_m.splitXW_all(oe_ref.x_op_err)\n",
    "       ##_,_, w_a,_,_,_,_ = supporting_routines_m.splitXW_all(oe_ref.x_a)\n",
    "       ##_,_, w_a_err,_,_,_,_ = supporting_routines_m.splitXW_all(oe_ref.x_a_err)\n",
    "       # _,_, w_truth1,_,_,_,_ = supporting_routines_m.splitXW_all(oe_ref.x_truth)\n",
    "        \n",
    "    # U & V:\n",
    "        _,_,u_op1, v_op1,_,_,_ = supporting_routines_m.splitX_all(oe_ref.x_op)\n",
    "        _,_,u_op_err1, v_op_err1,_,_,_ = supporting_routines_m.splitX_all(oe_ref.x_op_err)\n",
    "        #_,_,u_a1, v_a1,_,_,_ = supporting_routines_m.splitX_all(oe_ref.x_a)\n",
    "        #_,_,u_a_err1, v_a_err1,_,_,_ = supporting_routines_m.splitX_all(oe_ref.x_a_err)\n",
    "        _,_,u_truth1, v_truth1,_,_,_ = supporting_routines_m.splitX_all(oe_ref.x_truth)\n",
    "        u_op2 = np.append(u_op2,u_op1)\n",
    "        u_op_err2 = np.append(u_op_err2,u_op_err1)\n",
    "        u_truth2 = np.append(u_truth2,u_truth1)\n",
    "        v_op2 = np.append(v_op2,v_op1)\n",
    "        v_op_err2 = np.append(v_op_err2,v_op_err1)\n",
    "        v_truth2 = np.append(v_truth2,v_truth1)          \n",
    "    # Compute magnitude using coordinates U and V\n",
    "        w_op1, w_op_err1 = supporting_routines_m.UV2Wvar(oe_ref.S_op.loc['00010_nu','00010_nu'],\n",
    "                                                  oe_ref.S_op.loc['00010_nv','00010_nv'],\n",
    "                                                  oe_ref.S_op.loc['00010_nu','00010_nv'],\n",
    "                                                  u_op1,v_op1)        \n",
    "        w_truth1 = np.sqrt( u_truth1**2 + v_truth1**2 )   \n",
    "        \n",
    "        # For wind components we compare absolute value only\n",
    "        # SSMIS cannot provide polarimetric measurements\n",
    "        # so comparing angular information is not a proper metric\n",
    "        # U component \n",
    "        \n",
    "\n",
    "        w_op2 = np.append(w_op2,w_op1)\n",
    "        w_op_err2 = np.append(w_op_err2,w_op_err1)\n",
    "        w_truth2 = np.append(w_truth2,w_truth1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        seasonal = np.append(seasonal,season_prof)\n",
    "        \n",
    "        lat_local = np.append(lat_local,lat1)\n",
    "        long_local = np.append(long_local,long1)\n",
    "        \n",
    "        print('index:')\n",
    "        print(ind)\n",
    "        \n",
    "    \n",
    "    plotInMap(lat_local, long_local, lat, long, KK, lat_skip, long_skip)\n",
    "    perSeasonPlots(w_truth2, w_op2, seasonal, KK, windType = 'W10m')\n",
    "    perSeasonPlots(u_truth2, u_op2, seasonal, KK, windType = 'U10m')\n",
    "    perSeasonPlots(v_truth2, v_op2, seasonal, KK, windType = 'V10m')\n",
    "    \n",
    "    rmse_local, mae_local, r2_local = regressPlots(w_truth2, w_op2, KK, windType = 'W10m')   \n",
    "    _, _, _ = regressPlots(u_truth2, u_op2, KK, windType = 'U10m')\n",
    "    _, _, _ = regressPlots(v_truth2, v_op2, KK, windType = 'V10m')\n",
    "    \n",
    "    rmse += rmse_local\n",
    "    mae += mae_local\n",
    "    r2 += r2_local\n",
    "    \n",
    "    #skipRatio = count_nc/(count_nc+len(w_op2)) # ratio of (skipped / total) points in the test dataset\n",
    "    \n",
    "    \n",
    "    \n",
    "    #if KK == 1: break\n",
    "\n",
    "rmse = rmse / KK\n",
    "mae = mae / KK\n",
    "r2 = r2 / KK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oe_ref.S_op.loc[['00010_nu','00010_nv'],['00010_nu','00010_nv']]\n",
    "Uu2 = oe_ref.S_op.loc['00010_nu','00010_nu']  # variance U\n",
    "Uv2 = oe_ref.S_op.loc['00010_nv','00010_nv']  # variance V \n",
    "Uuv = oe_ref.S_op.loc['00010_nu','00010_nv']  # covariance UV\n",
    "\n",
    "u = np.float64(u_op1.values)\n",
    "v = np.float64(v_op1.values)\n",
    "w = np.sqrt(u**2+v**2)\n",
    "\n",
    "bruteUncertainty = np.sqrt(np.float64(u_op_err1.values)**2+np.float64(v_op_err1.values)**2)\n",
    "\n",
    "combinedUncertainty = np.sqrt((1/(w**2))*(Uu2*(u)**2+Uv2*(v)**2+2*u*v*Uuv))\n",
    "\n",
    "print(oe_ref.d_i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windDisambiguation(oe_ref,forwardRT,forwardKwArgs):\n",
    "    # Procedure proposed in:\n",
    "    # M. Bettenhausen, et al, \"A Nonlinear Optimization Algorithm \n",
    "    # for WindSat Wind Vector Retrievals\", IEEE Trans. Geo. Rem. Sens.,\n",
    "    # Vol. 44, No. 3, March 2006\n",
    "    \n",
    "    # First retrieved wind\n",
    "    #_, _, u_op, v_op = supporting_routines_m.splitXUV(oe_ref.x_op)\n",
    "    _,_,u_op, v_op,_,_,_ = supporting_routines_m.splitX_all(oe_ref.x_op)\n",
    "    \n",
    "    # Most of the retrieval parameters are the same as for the original retrieval:\n",
    "    x_vars = oe_ref.x_vars \n",
    "    y_vars = oe_ref.y_vars \n",
    "    y_obs = oe_ref.y_obs \n",
    "    S_a = oe_ref.S_a\n",
    "    S_y = oe_ref.S_y\n",
    "    \n",
    "    S_b = oe_ref.S_b\n",
    "    b_vars = oe_ref.b_vars\n",
    "    b_p = oe_ref.b_p\n",
    "    \n",
    "    #forwardRT = oe_ref.forwardRT\n",
    "    #forwardKwArgs = oe_ref.forwardKwArgs\n",
    "    x_truth = oe_ref.x_truth \n",
    "    \n",
    "    mini = 100000\n",
    "    \n",
    "    rot = np.array([[0,-1],[1,0]]) # Rotation matrix (90 deg rotation)\n",
    "    # 4 ambiguities (1 per quadrant):\n",
    "    aprio1 = np.array([[np.float64(u_op.values)],[np.float64(v_op.values)]])   \n",
    "    aprio2 = np.dot(rot,aprio1)\n",
    "    aprio3 = np.dot(rot,aprio2)\n",
    "    aprio4 = np.dot(rot,aprio3)\n",
    "    \n",
    "    # Re-use the first retrieved atmospheric state as the new a-priori dataset\n",
    "    x_a1 = oe_ref.x_op.copy()\n",
    "    x_a1['00010_nu'] = aprio1[0,0] # a-priori wind 1: as retrieved\n",
    "    x_a1['00010_nv'] = aprio1[1,0]\n",
    "    oe_ref1 = pyOE.optimalEstimation(\n",
    "            x_vars, # state variable names\n",
    "            x_a1,  # a priori\n",
    "            S_a, # a priori uncertainty\n",
    "            y_vars,  # measurement variable names\n",
    "            y_obs, # observations\n",
    "            S_y, # observation uncertainty\n",
    "            forwardRT, # forward Operator\n",
    "            forwardKwArgs=forwardKwArgs, # additonal function arguments\n",
    "            x_truth=x_truth, # true profile\n",
    "            b_vars=b_vars,   # Parameter vector variable names\n",
    "            b_p=b_p,        # Parameter vector \n",
    "            S_b=S_b        # Parameters error covariance matrix \n",
    "            )\n",
    "\n",
    "    oe_ref1.doRetrieval()\n",
    "    \n",
    "    # X**2 (eq (2) in reference), goodness of fit of forward model:\n",
    "    # TODO: S_y should be S_y+S_b' # note Mario    \n",
    "    numero = np.dot(np.transpose(y_obs-oe_ref1.y_i[-1]),\n",
    "                    np.dot(np.linalg.inv(oe_ref1.S_y),\n",
    "                           (y_obs-oe_ref1.y_i[-1])))\n",
    "    #if oe_ref1.d_i2[-1]<mini:\n",
    "    if numero < mini:\n",
    "        mini = numero #oe_ref1.d_i2[-1]\n",
    "        oe_return = oe_ref1\n",
    "        index = 1\n",
    "        \n",
    "    #_, _,u1, v1 = supporting_routines_m.splitXUV(oe_ref1.x_op)\n",
    "# 2nd vector\n",
    "    x_a2 = oe_ref.x_op.copy()\n",
    "    x_a2['00010_nu'] = aprio2[0,0]\n",
    "    x_a2['00010_nv'] = aprio2[1,0]\n",
    "    oe_ref2 = pyOE.optimalEstimation(\n",
    "            x_vars, # state variable names\n",
    "            x_a2,  # a priori\n",
    "            S_a, # a priori uncertainty\n",
    "            y_vars,  # measurement variable names\n",
    "            y_obs, # observations\n",
    "            S_y, # observation uncertainty\n",
    "            forwardRT, # forward Operator\n",
    "            forwardKwArgs=forwardKwArgs, # additonal function arguments\n",
    "            x_truth=x_truth, # true profile\n",
    "            b_vars=b_vars,   # Parameter vector variable names\n",
    "            b_p=b_p,        # Parameter vector \n",
    "            S_b=S_b        # Parameters error covariance matrix \n",
    "            )\n",
    "\n",
    "    oe_ref2.doRetrieval()\n",
    "    \n",
    "    # X**2 (eq (2) in reference), goodness of fit of forward model:\n",
    "    # TODO: S_y should be S_y+S_b' # note Mario\n",
    "    numero = np.dot(np.transpose(y_obs-oe_ref2.y_i[-1]),\n",
    "                    np.dot(np.linalg.inv(oe_ref2.S_y),\n",
    "                           (y_obs-oe_ref2.y_i[-1])))    \n",
    "    #if oe_ref2.d_i2[-1]<mini:\n",
    "    if numero < mini:\n",
    "        mini = numero #oe_ref2.d_i2[-1]\n",
    "        oe_return = oe_ref2\n",
    "        index = 2\n",
    "        \n",
    "    #_, _,u2, v2 = supporting_routines_m.splitXUV(oe_ref2.x_op)\n",
    "# 3rd vector\n",
    "    x_a3= oe_ref.x_op.copy()\n",
    "    x_a3['00010_nu'] = aprio3[0,0]\n",
    "    x_a3['00010_nv'] = aprio3[1,0]\n",
    "    oe_ref3 = pyOE.optimalEstimation(\n",
    "            x_vars, # state variable names\n",
    "            x_a3,  # a priori\n",
    "            S_a, # a priori uncertainty\n",
    "            y_vars,  # measurement variable names\n",
    "            y_obs, # observations\n",
    "            S_y, # observation uncertainty\n",
    "            forwardRT, # forward Operator\n",
    "            forwardKwArgs=forwardKwArgs, # additonal function arguments\n",
    "            x_truth=x_truth, # true profile\n",
    "            b_vars=b_vars,   # Parameter vector variable names\n",
    "            b_p=b_p,        # Parameter vector \n",
    "            S_b=S_b        # Parameters error covariance matrix \n",
    "            )\n",
    "\n",
    "    oe_ref3.doRetrieval()\n",
    "    \n",
    "    # X**2 (eq (2) in reference), goodness of fit of forward model:\n",
    "    # TODO: S_y should be S_y+S_b' # note Mario    \n",
    "    numero = np.dot(np.transpose(y_obs-oe_ref3.y_i[-1]),\n",
    "                    np.dot(np.linalg.inv(oe_ref3.S_y),\n",
    "                           (y_obs-oe_ref3.y_i[-1])))     \n",
    "    \n",
    "    #if oe_ref3.d_i2[-1]<mini:\n",
    "    if numero < mini:\n",
    "        mini = numero #oe_ref3.d_i2[-1]\n",
    "        oe_return = oe_ref3\n",
    "        index = 3\n",
    "        \n",
    "    #_, _,u3, v3 = supporting_routines_m.splitXUV(oe_ref3.x_op)\n",
    "# 4th vector\n",
    "    x_a4 = oe_ref.x_op.copy()\n",
    "    x_a4['00010_nu'] = aprio4[0,0]\n",
    "    x_a4['00010_nv'] = aprio4[1,0]\n",
    "    oe_ref4 = pyOE.optimalEstimation(\n",
    "            x_vars, # state variable names\n",
    "            x_a4,  # a priori\n",
    "            S_a, # a priori uncertainty\n",
    "            y_vars,  # measurement variable names\n",
    "            y_obs, # observations\n",
    "            S_y, # observation uncertainty\n",
    "            forwardRT, # forward Operator\n",
    "            forwardKwArgs=forwardKwArgs, # additonal function arguments\n",
    "            x_truth=x_truth, # true profile\n",
    "            b_vars=b_vars,   # Parameter vector variable names\n",
    "            b_p=b_p,        # Parameter vector \n",
    "            S_b=S_b        # Parameters error covariance matrix \n",
    "            )\n",
    "\n",
    "    oe_ref4.doRetrieval()\n",
    "    \n",
    "    # X**2 (eq (2) in reference), goodness of fit of forward model:\n",
    "    # TODO: S_y should be S_y+S_b' # note Mario\n",
    "    numero = np.dot(np.transpose(y_obs-oe_ref4.y_i[-1]),\n",
    "                    np.dot(np.linalg.inv(oe_ref4.S_y),\n",
    "                           (y_obs-oe_ref4.y_i[-1])))     \n",
    "    \n",
    "    #if oe_ref4.d_i2[-1]<mini:\n",
    "    if numero < mini:\n",
    "        mini = numero #oe_ref4.d_i2[-1]\n",
    "        oe_return = oe_ref4\n",
    "        index = 4\n",
    "        \n",
    "    #_, _,u4, v4 = supporting_routines_m.splitXUV(oe_ref4.x_op)\n",
    "    print(index)\n",
    "\n",
    "    return oe_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardRT(X, myProfiles_a, ssmiRttov_a):\n",
    "    \n",
    "    # TODO: Add assertions, tests *** mario\n",
    "\n",
    "    # X contains T, Q and W10, lets split the vector\n",
    "    #temperature, humidity, wind10m = supporting_routines_m.splitX(X)\n",
    "    \n",
    "    # if wind speed in components:\n",
    "    #temperature, humidity, u10m, v10m = supporting_routines_m.splitXUV(X)\n",
    "    temperature, humidity, u10m, v10m, bp2m, bt2m, btsk \\\n",
    "    = supporting_routines_m.splitX_all(X)\n",
    "    #temperature, humidity, wind10m, bp2m, bt2m, btsk = supporting_routines_m.splitXW_all(X)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # humdity is in log10 scale, convert to linear in kg/kg\n",
    "    humidity = (10**humidity) / 1000.\n",
    "    # or abs_humidity? *** note mario\n",
    "\n",
    "    myProfiles_a.T = reshape4profiles(temperature.to_numpy(dtype=np.float64))  \n",
    "    myProfiles_a.Q = reshape4profiles(humidity.to_numpy(dtype=np.float64))  \n",
    "\n",
    "    myProfiles_a.S2m[:,0] = reshape4profiles(\n",
    "        bp2m.to_numpy(dtype=np.float64)).flatten() # surface pressure\n",
    "    myProfiles_a.S2m[:,1] = reshape4profiles(\n",
    "        bt2m.to_numpy(dtype=np.float64)).flatten()  # 2m temperature\n",
    "    myProfiles_a.Skin[:,0] = reshape4profiles(\n",
    "        btsk.to_numpy(dtype=np.float64)).flatten() \n",
    "    \n",
    "    # if wind in components:\n",
    "    myProfiles_a.S2m[:,3] = reshape4profiles(\n",
    "        u10m.to_numpy(dtype=np.float64)).flatten()  #  10m windspeed, u component\n",
    "    myProfiles_a.S2m[:,4] = reshape4profiles(\n",
    "        v10m.to_numpy(dtype=np.float64)).flatten()  #  10m windspeed, v component  \n",
    "    \n",
    "   \n",
    "    ssmiRttov_a.Profiles = myProfiles_a\n",
    "    \n",
    "    ssmiRttov_a.SurfEmisRefl[:,:,:] = -1. # need to \"reset\" to -1 every time RTTOV is called; \n",
    "    # -1 indicates to RTTOV to use internal values for surface emissivity.\n",
    "\n",
    "    try:\n",
    "        ssmiRttov_a.runDirect()\n",
    "    except pyrttov.RttovError as e:\n",
    "        sys.stderr.write(\"Error running RTTOV direct model: {!s}\".format(e))\n",
    "        sys.exit(1)    \n",
    "        \n",
    "    #print(ssmiRttov.BtRefl[:, :].shape)\n",
    "    #print(ssmiRttov.BtRefl[:, :])\n",
    "    \n",
    "    if(ssmiRttov_a.BtRefl[:, :].shape[0]==1):\n",
    "        TB = ssmiRttov_a.BtRefl[0, :].T\n",
    "    else:\n",
    "        TB = ssmiRttov_a.BtRefl[:, :].T\n",
    "    \n",
    "    return TB\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def reshape4profiles(profiles):\n",
    "    # \"profiles\" is a numpy array\n",
    "    # \"profiles\" can contain 1 or more profiles\n",
    "    # \"profiles\" has dimensions (nlevels, nprofiles)\n",
    "    # \"outProfiles\" has dimensions (nprofiles,nlevels) (as needed in RTTOV)\n",
    "    \n",
    "    if (len(profiles.shape)==1):\n",
    "        outProfiles = profiles.reshape(1,profiles.shape[0]).copy()\n",
    "    else:\n",
    "        outProfiles = profiles.T.copy() #profiles.reshape(profiles.shape[1]\n",
    "            #                          ,profiles.shape[0]) \n",
    "    return outProfiles    \n",
    "\n",
    "def expand2nprofiles(n, nprof):\n",
    "    # Transform 1D array to a [nprof, nlevels] array\n",
    "    outp = np.empty((nprof, len(n)), dtype=n.dtype)\n",
    "    for i in range(nprof):\n",
    "        outp[i, :] = n[:]\n",
    "    return outp\n",
    "\n",
    "\n",
    "def forward_b_init(pressure, salinity, lat, long, datetime_obs64, \n",
    "                   zenithAngle, myProfiles):\n",
    "    \n",
    "    if (len(pressure.shape)==1):\n",
    "        nprofiles = 1\n",
    "    else:\n",
    "        nprofiles =  pressure.shape[1]\n",
    "    \n",
    "    # The rest of the code uses datetime64 format (numpy), but I have to pass the obs date as integers to RTTOV\n",
    "    datetime_obs = supporting_routines_m.datetime64_to_datetime(datetime_obs64)\n",
    "    \n",
    "    s2m = np.zeros((nprofiles,6), dtype=np.float64) # s2m has 6 elements (docs RTTOV)\n",
    "    \n",
    "    angles = np.zeros((nprofiles,4), dtype=np.float64) # angles has 4 elements (docs RTTOV)\n",
    "    angles[:,0] = zenithAngle\n",
    "    \n",
    "    \n",
    "    # for RTTOV 13 skin is 9 elements long:\n",
    "    skin = np.zeros((nprofiles,9), dtype=np.float64) # skin has 9 elements (docs RTTOV)\n",
    "    skin[:,1] = salinity\n",
    "        \n",
    "    surftype = np.zeros((nprofiles,2), dtype=np.int32) # surftype has 2 elements (docs RTTOV)\n",
    "    surftype[:,:] = 1 # [sea, ocean] Harcoded for now, TODO *** mario\n",
    "    \n",
    "    \n",
    "    surfgeom = np.zeros((nprofiles,3), dtype=np.float64) # surfgeom has 3 elements (docs RTTOV)\n",
    "    surfgeom[:,0] = lat\n",
    "    surfgeom[:,1] = long\n",
    "    # surfgeom[:,2]=0 # elevation harcoded to 0 for now, TODO *** mario\n",
    "    \n",
    "    date_times = np.zeros((nprofiles,6), dtype=np.int32) # date_times has 6 elements (docs RTTOV)\n",
    "    date_times[:,0] = datetime_obs.year\n",
    "    date_times[:,1] = datetime_obs.month\n",
    "    date_times[:,2] = datetime_obs.day\n",
    "    date_times[:,3] = datetime_obs.hour\n",
    "    date_times[:,4] = datetime_obs.minute\n",
    "    date_times[:,5] = datetime_obs.second\n",
    "    \n",
    "    \n",
    "    myProfiles.GasUnits = 1  # kg/kg (see RTTOV doc. for other options) # Harcoded for now, TODO *** mario\n",
    "    myProfiles.P = reshape4profiles(pressure) \n",
    "    myProfiles.S2m = s2m\n",
    "    myProfiles.Angles = angles\n",
    "    myProfiles.Skin = skin\n",
    "    myProfiles.SurfType = surftype\n",
    "    myProfiles.SurfGeom = surfgeom\n",
    "    myProfiles.DateTimes = date_times\n",
    "    \n",
    "    #return myProfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotInMap(lat2, long2, lat, long, indice, lat_s = None, long_s = None):\n",
    "    \n",
    "    #lat2 = profiles.lat.values\n",
    "    #long2 = profiles.long.values\n",
    "\n",
    "    plt.figure(figsize=(13,6.2))\n",
    "    \n",
    "    ax = plt.subplot(111, projection=ccrs.PlateCarree())\n",
    "\n",
    "    ax.scatter(long,\\\n",
    "                   lat,marker='.',color='red')\n",
    "    ax.scatter(long2,\\\n",
    "                   lat2,marker='o',color='blue')\n",
    "    if (lat_s is not None)and(long_s is not None):\n",
    "        ax.scatter(long_s,\\\n",
    "                   lat_s,marker='o',color='yellow')\n",
    "                \n",
    "    ax.coastlines();\n",
    "\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax.set_xlabel('Longitude [deg]')\n",
    "    ax.set_ylabel('Latitude [deg]')\n",
    "\n",
    "    ax.stock_img();\n",
    "\n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(), linewidth=2, \n",
    "                      color='black', alpha=0.5, linestyle='--', draw_labels=True)\n",
    "    gl.xlabels_top = False\n",
    "    gl.ylabels_left = False\n",
    "    gl.ylabels_right=True\n",
    "    gl.xlines = True\n",
    "    gl.xlocator = mticker.FixedLocator([-180, -120, -60, 0, 60, 120, 180])\n",
    "    gl.ylocator = mticker.FixedLocator([-60, -30, 0, 30, 60])\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "\n",
    "    plt.savefig('Loc_Fold_'+str(indice)+'.png', dpi=300)\n",
    "\n",
    "def perSeasonPlots(truth,optimized,seasonal, indice, windType = 'W10m'):\n",
    "    \n",
    "    colors = {'DJF':'blue', 'MAM':'green', 'JJA':'orange', 'SON':'purple'}\n",
    "    \n",
    "    df = pd.DataFrame(dict(Truth=truth, Optimized=optimized, Season = seasonal))\n",
    "    \n",
    "    seasonGroup = df.groupby('Season')\n",
    "\n",
    "    for name, group in seasonGroup:\n",
    "        #print name\n",
    "        #print group \n",
    "        \n",
    "        w_truth = group['Truth'].values[:]\n",
    "        w_opt = group['Optimized'].values[:]\n",
    "\n",
    "        error_local = w_truth - w_opt\n",
    "        mean_error_local = np.mean( error_local )\n",
    "        median_error_local = np.median( error_local )\n",
    "        multiplicativeBias = np.mean(w_truth) / np.mean(w_opt)\n",
    "\n",
    "        rmse_local = np.sqrt(mean_squared_error(w_truth, w_opt)) \n",
    "        mae_local = median_absolute_error(w_truth, w_opt)\n",
    "        r2_local = r2_score(w_truth, w_opt)\n",
    "\n",
    "        \n",
    "        wt = np.reshape( w_truth, (len(w_truth),1) ) # for using with .fit below\n",
    "        \n",
    "        # Ordinary least squares:\n",
    "        regr = LinearRegression()\n",
    "    \n",
    "        # Robust fit with Ransac algo. (sklearn lib.)\n",
    "        ransac = RANSACRegressor()\n",
    "        \n",
    "        # HuberRegressor\n",
    "        #huber = HuberRegressor()\n",
    "\n",
    "        # Train the model using the training sets\n",
    "        \n",
    "            # OLS fit:\n",
    "        regr.fit(wt, w_opt)\n",
    "        # Ransac fit:\n",
    "        ransac.fit(wt, w_opt)\n",
    "        # Huber fit\n",
    "        #huber.fit(wt, w_opt)\n",
    "        \n",
    "        # mask inlier-outlier from Ransac:\n",
    "        inlier_mask = ransac.inlier_mask_\n",
    "        outlier_mask = np.logical_not(inlier_mask)\n",
    "        \n",
    "        # mask inlier-outlier from Huber:     \n",
    "        #outlier_mask = huber.outliers_\n",
    "        #inlier_mask = np.logical_not(outlier_mask)\n",
    "    \n",
    "        # Make predictions using the testing set\n",
    "        # OLS:\n",
    "        wind_pred = regr.predict(wt)  \n",
    "        # Ransac:\n",
    "        wind_ransac = ransac.predict(wt)\n",
    "        # Huber:\n",
    "        #wind_huber = huber.predict(wt)   \n",
    "    \n",
    "        fig, (ax1,ax2) = plt.subplots(ncols=2, sharey = True)\n",
    "        # Plot outputs\n",
    "        ax1.scatter(w_truth, w_opt,  c=group['Season'].map(colors), alpha= 0.5, label = 'Optimal vs True')\n",
    "        ax1.plot(w_truth, wind_pred, color='black', linewidth=1.5, label = 'Linear regression')\n",
    "        ax1.plot(w_truth, w_truth, color='gray', linewidth=1.5, label = 'Slope 1 line')\n",
    "\n",
    "        ax1.set_ylabel('NS Wind Speed [m/s], Retrieved')\n",
    "        ax1.set_xlabel('NS Wind Speed [m/s], True')\n",
    "        ax1.grid(True)\n",
    "        ax1.set_title('OLS '+windType)\n",
    "        ax1.text(\n",
    "            0.95,\n",
    "            0.05,\n",
    "            '%s\\nm = %.3g\\nb = %.3g%s\\nrmse = %.3g%s\\nmae = %.3g%s\\nr$^2$ = %.3g' % (\n",
    "                '$mx+b$',\n",
    "                np.float(regr.coef_),\n",
    "                np.float(regr.intercept_),'m/s',\n",
    "                rmse_local,'m/s',\n",
    "                mae_local,'m/s',\n",
    "                r2_local),\n",
    "            horizontalalignment='right',\n",
    "            verticalalignment='bottom',\n",
    "            transform=ax1.transAxes)\n",
    "        \n",
    "        # Plot Ransac\n",
    "        ax2.scatter(w_truth[inlier_mask], w_opt[inlier_mask],  \n",
    "                c=group['Season'][inlier_mask].map(colors), alpha = 0.5, label = 'Retrieved')\n",
    "        ax2.scatter(w_truth[outlier_mask], w_opt[outlier_mask],  \n",
    "                color='magenta', alpha = 0.4, label = 'Outlier')\n",
    "        ax2.plot(w_truth, wind_ransac, color='black', linewidth=1.5, label = 'Regression')\n",
    "        ax2.plot(w_truth, w_truth, color='gray', linewidth=1.5, label = 'm = 1')\n",
    "    \n",
    "        ax2.legend()\n",
    "        ax2.set_xlabel('NS Wind Speed [m/s], True')\n",
    "        ax2.grid(True)\n",
    "        ax2.set_title('Ransac '+windType)\n",
    "        ax2.text(\n",
    "            0.95,\n",
    "            0.05,\n",
    "            '%s\\nm = %.3g\\nb = %.3g%s\\nrmse = %.3g%s\\nmae = %.3g%s\\nr$^2$ = %.3g' % (\n",
    "                '$mx+b$',\n",
    "                np.float(ransac.estimator_.coef_),\n",
    "                np.float(ransac.estimator_.intercept_),'m/s',\n",
    "                np.sqrt(mean_squared_error(w_truth[inlier_mask], w_opt[inlier_mask])) ,'m/s',\n",
    "                median_absolute_error(w_truth[inlier_mask], w_opt[inlier_mask]),'m/s',\n",
    "                np.float(r2_score(w_truth[inlier_mask], w_opt[inlier_mask]))),\n",
    "            horizontalalignment='right',\n",
    "            verticalalignment='bottom',\n",
    "            transform=ax2.transAxes)\n",
    "\n",
    "        plt.legend(loc=(0.02,0.73), prop={'size': 9}) \n",
    "        plt.savefig('seas_wind'+name+windType+'_'+str(indice), dpi=300)  \n",
    "        \n",
    "        # Histogram\n",
    "        bins_all = 5\n",
    "\n",
    "        fig, ax = plt.subplots(1)\n",
    "        ax.hist(error_local, bins = bins_all, label=name)\n",
    "        ax.legend()\n",
    "        ax.text(0.95,0.75,\n",
    "                'Mean error = %.3g\\nMedian error = %.3g\\nBias (M) = %.3g' % ( \n",
    "                    mean_error_local, \n",
    "                    median_error_local,\n",
    "                    multiplicativeBias),\n",
    "                horizontalalignment='right',\n",
    "                verticalalignment='top',\n",
    "                transform=ax.transAxes)\n",
    "    \n",
    "        ax.grid(True)\n",
    "        plt.savefig('seas_err'+name+windType+'_'+str(indice), dpi=300)\n",
    "    \n",
    "def regressPlots(truth, optimized, indice, windType = 'Wind'):\n",
    "    \n",
    "        #error_local = truth - optimized\n",
    "        #mean_error_local = np.mean( error_local )\n",
    "        #median_error_local = np.median( error_local )\n",
    "    \n",
    "        rmse_local = np.sqrt(mean_squared_error(truth, optimized)) \n",
    "        mae_local = median_absolute_error(truth, optimized)\n",
    "        r2_local = r2_score(truth, optimized)\n",
    "\n",
    "    \n",
    "        # Ordinary least squares:\n",
    "        regr = LinearRegression()\n",
    "    \n",
    "        # Robust fit with Ransac algo. (sklearn lib.)\n",
    "        ransac = RANSACRegressor()\n",
    "    \n",
    "        # Train the model using the training sets\n",
    "        wt = np.reshape(truth,(len(truth),1)) # for using with .fit below\n",
    "    \n",
    "        # OLS fit:\n",
    "        regr.fit(wt, optimized)\n",
    "        # Ransac fit:\n",
    "        ransac.fit(wt, optimized)\n",
    "        # mask inlier-outlier from Ransac:\n",
    "        inlier_mask = ransac.inlier_mask_\n",
    "        outlier_mask = np.logical_not(inlier_mask)\n",
    "    \n",
    "        # Make predictions using the testing set\n",
    "        # OLS:\n",
    "        wind_pred = regr.predict(wt)  \n",
    "        # Ransac:\n",
    "        wind_ransac = ransac.predict(wt)\n",
    "    \n",
    "        fig, (ax1,ax2) = plt.subplots(ncols=2, sharey = True)\n",
    "        # Plot outputs\n",
    "        ax1.scatter(truth, optimized,  color='dodgerblue', alpha = 0.5, label = 'Optimal vs True')\n",
    "        ax1.plot(truth, wind_pred, color='black', linewidth=1.5, label = 'Linear regression')\n",
    "        ax1.plot(truth, truth, color='gray', linewidth=1.5, label = 'Slope 1 line')\n",
    "\n",
    "        ax1.set_ylabel('NS Wind Speed [m/s], Retrieved')\n",
    "        ax1.set_xlabel('NS Wind Speed [m/s], True')\n",
    "        ax1.grid(True)\n",
    "        ax1.set_title('OLS '+windType)\n",
    "        ax1.text(\n",
    "            0.95,\n",
    "            0.05,\n",
    "            '%s\\nm = %.3g\\nb = %.3g%s\\nrmse = %.3g%s\\nmae = %.3g%s\\nr$^2$ = %.3g' % (\n",
    "            '$mx+b$',\n",
    "            np.float(regr.coef_),\n",
    "            np.float(regr.intercept_),'m/s',\n",
    "            rmse_local,'m/s',\n",
    "            mae_local,'m/s',\n",
    "            r2_local),\n",
    "            horizontalalignment='right',\n",
    "            verticalalignment='bottom',\n",
    "            transform=ax1.transAxes)\n",
    "\n",
    "        # Plot outputs\n",
    "        ax2.scatter(truth[inlier_mask], optimized[inlier_mask],  \n",
    "                color='dodgerblue', alpha = 0.5, label = 'Retrieved')\n",
    "        ax2.scatter(truth[outlier_mask], optimized[outlier_mask],  \n",
    "                color='magenta', alpha = 0.5, label = 'Outlier')\n",
    "        ax2.plot(truth, wind_ransac, color='black', linewidth=1.5, label = 'Regression')\n",
    "        ax2.plot(truth, truth, color='gray', linewidth=1.5, label = 'm = 1')\n",
    "    \n",
    "        ax2.legend()\n",
    "        ax2.set_xlabel('NS Wind Speed [m/s], True')\n",
    "        ax2.grid(True)\n",
    "        ax2.set_title('Ransac '+windType)\n",
    "        ax2.text(\n",
    "            0.95,\n",
    "            0.05,\n",
    "            '%s\\nm = %.3g\\nb = %.3g%s\\nrmse = %.3g%s\\nmae = %.3g%s\\nr$^2$ = %.3g' % (\n",
    "            '$mx+b$',\n",
    "            np.float(ransac.estimator_.coef_),\n",
    "            np.float(ransac.estimator_.intercept_),'m/s',\n",
    "            np.sqrt(mean_squared_error(truth[inlier_mask], optimized[inlier_mask])) ,'m/s',\n",
    "            median_absolute_error(truth[inlier_mask], optimized[inlier_mask]),'m/s',\n",
    "            np.float(r2_score(truth[inlier_mask], optimized[inlier_mask]))),\n",
    "            horizontalalignment='right',\n",
    "            verticalalignment='bottom',\n",
    "            transform=ax2.transAxes)\n",
    "\n",
    "        plt.legend(loc=(0.02,0.73), prop={'size': 9}) \n",
    "        plt.savefig('windR_'+windType+str(indice), dpi=300)\n",
    "        \n",
    "        return rmse_local, mae_local, r2_local\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
