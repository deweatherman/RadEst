{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import datetime \n",
    "import time\n",
    "from datetime import datetime \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#import sklearn\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error,r2_score\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor, HuberRegressor\n",
    "\n",
    "\n",
    "import pyOptimalEstimation as pyOE\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "from cmocean import cm as cmo\n",
    "\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('support')\n",
    "\n",
    "import supporting_routines_m \n",
    "\n",
    "import os\n",
    "\n",
    "rttov_installdir = '/home/mario/myLibs/rrtov13/rttov130'\n",
    "\n",
    "sys.path.append(rttov_installdir+'/wrapper')\n",
    "import pyrttov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aprio_dir = '/home/mario/Data/RadEst_crossVal_data/crossVal_aprioriData/'\n",
    "prior_all = xr.open_dataset(aprio_dir+'nwpsaf.nc') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of levels for the profiles in the priors\n",
    "# Useful to define here in order to initizalize the RTTOV instrument\n",
    "nlevels = len(prior_all['height'])\n",
    "nprofiles = 1\n",
    "NthreadsF = 1 #os.cpu_count()\n",
    "NthreadsFM = 4 #os.cpu_count()\n",
    "NprofsPerCallFM = 10 # ?Roughly speaking number of variables (e.g. 279) / Number of threads (e.g. 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channels corrispondence:\n",
    "\n",
    "# from: D. B. Kunkee et al, \"Design and Evaluation of the First \n",
    "# Special Sensor Microwave Imager/Sounder\", IEEE Trans. Geosc. Rem. Sens. \n",
    "# Vol. 46, NO. 4, April 2008.\n",
    "# Table 1\n",
    "# Ch. 1 - 50.3 GHz Hpol (check note on pol at source for this channel) \n",
    "# Ch. 12 - 19.35 GHz Hpol\n",
    "# Ch. 13 - 19.35 GHz Vpol\n",
    "# Ch. 14 - 22.235 GHz Vpol\n",
    "# Ch. 15 - 37 GHz Hpol\n",
    "# Ch. 16 - 37 GHz Vpol\n",
    "\n",
    "ssmiRttov = pyrttov.Rttov()\n",
    "\n",
    "# SSMIS:\n",
    "nchan_ssmi = 5\n",
    "chan_list_ssmi = (12,13,14,15,16) #(1,2,3,4,5,6,7,12,13,14,15,16,23,24) #(1,12,13,14,15,16) #  #\n",
    "ssmiRttov.FileCoef = '{}/{}'.format(rttov_installdir,\n",
    "                                    \"rtcoef_rttov13/rttov7pred54L/rtcoef_dmsp_16_ssmis.dat\")\n",
    "\n",
    "ssmiRttov.Options.AddInterp = True\n",
    "#ssmiRttov.Options.InterpMode = 4\n",
    "ssmiRttov.Options.CO2Data = False\n",
    "ssmiRttov.Options.VerboseWrapper = False\n",
    "ssmiRttov.Options.DoCheckinput = False\n",
    "ssmiRttov.Options.UseQ2m = False\n",
    "ssmiRttov.Options.ApplyRegLimits = True\n",
    "ssmiRttov.Options.Verbose = False\n",
    "ssmiRttov.Options.Switchrad = True\n",
    "ssmiRttov.Options.FastemVersion = 6 \n",
    "ssmiRttov.Options.Nthreads = NthreadsF\n",
    "\n",
    "# Load the instruments: for HIRS and MHS do not supply a channel list and\n",
    "# so read all channels\n",
    "try:\n",
    "    ssmiRttov.loadInst(chan_list_ssmi)\n",
    "except pyrttov.RttovError as e:\n",
    "    sys.stderr.write(\"Error loading instrument(s): {!s}\".format(e))\n",
    "    sys.exit(1)\n",
    "\n",
    "# Load Atlases: (if any)    \n",
    "#ssmiRttov.SurfEmisRefl = np.zeros((4,nprofiles,nchan_ssmi), dtype=np.float64) # RTTOVv12 used (2,nprof,nchan)\n",
    "\n",
    "# Definition of the observation variables\n",
    "y_vars = np.array(chan_list_ssmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY FOR MULTIPLE PROFILES CALL TESTING\n",
    "\n",
    "ssmiRttovM = pyrttov.Rttov()\n",
    "\n",
    "# SSMIS:\n",
    "nchan_ssmiM = 5\n",
    "chan_list_ssmiM = (12,13,14,15,16) #(1,2,3,4,5,6,7,12,13,14,15,16,23,24) #(1,12,13,14,15,16) #  #\n",
    "ssmiRttovM.FileCoef = '{}/{}'.format(rttov_installdir,\n",
    "                                    \"rtcoef_rttov13/rttov7pred54L/rtcoef_dmsp_16_ssmis.dat\")\n",
    "\n",
    "ssmiRttovM.Options.AddInterp = True\n",
    "#ssmiRttovM.Options.InterpMode = 4\n",
    "ssmiRttovM.Options.CO2Data = False\n",
    "ssmiRttovM.Options.VerboseWrapper = False\n",
    "ssmiRttovM.Options.DoCheckinput = False\n",
    "ssmiRttovM.Options.UseQ2m = False\n",
    "ssmiRttovM.Options.ApplyRegLimits = True\n",
    "ssmiRttovM.Options.Verbose = False\n",
    "ssmiRttovM.Options.Switchrad = True\n",
    "ssmiRttovM.Options.FastemVersion = 6 \n",
    "ssmiRttovM.Options.Nthreads = NthreadsFM\n",
    "ssmiRttovM.Options.NprofsPerCall = NprofsPerCallFM\n",
    "\n",
    "# Load the instruments: for HIRS and MHS do not supply a channel list and\n",
    "# so read all channels\n",
    "try:\n",
    "    ssmiRttovM.loadInst(chan_list_ssmiM)\n",
    "except pyrttov.RttovError as e:\n",
    "    sys.stderr.write(\"Error loading instrument(s): {!s}\".format(e))\n",
    "    sys.exit(1)\n",
    "\n",
    "# Load Atlases: (if any)    \n",
    "#ssmiRttovM.SurfEmisRefl = np.zeros((4,279,nchan_ssmi), dtype=np.float64) # RTTOVv12 used (2,nprof,nchan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Channels 1-7, 12-16, 23, 24 (values from Deblonde-English 2003) (sigma or std)\n",
    "y_noise = pd.Series(\n",
    "    [\n",
    "        #1.5, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 2.4, 1.27, 1.44, 3.0, 1.34, 0.46, 0.47\n",
    "        2.4, 1.27, 1.44, 3.0, 1.34\n",
    "   ],\n",
    "    index=y_vars\n",
    ")\n",
    "\n",
    "# Variance values > std**2\n",
    "S_y = pd.DataFrame(\n",
    "    np.diag(y_noise.values**2),\n",
    "    index=y_vars,\n",
    "    columns=y_vars,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the indices of the \"local prior\":\n",
    "# we will call local prior to the prior built\n",
    "# using a geographical area \"nearby\" the observation\n",
    "# location (i.e. a bounding box around the observation location). \n",
    "# All the atmospheric states within such a box \n",
    "# Define our a-priori knowledge (in the spatial domain)\n",
    "\n",
    "lat_min = -90.0\n",
    "lat_max = -40.0\n",
    "long_min = -180.0\n",
    "long_max = 180.0\n",
    "\n",
    "\n",
    "# Create simplified mask array: only points within bounding box will be selected\n",
    "lat_long_mask = np.array([(prior_all['lat'].values[:]>lat_min)&(\n",
    "                             prior_all['lat'].values[:]<lat_max)&\n",
    "                           ((prior_all['long'].values[:]>long_min)&(\n",
    "                               prior_all['long'].values[:]<long_max))])\n",
    "lat_long_mask=lat_long_mask.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XARRAY has much better ways to deal with masking arrays, etc. (e.g. xarray.where or dataarray.where)\n",
    "# I encourage the reader to check them out; for now I simply mask out by indexing:\n",
    "\n",
    "# Creating a time index for the local prior:\n",
    "times1 = prior_all['Time'].values[lat_long_mask]\n",
    "\n",
    "# Time in the original dataset is in terms of a timestam (i.e. seconds since a date in the 70's)\n",
    "# So I map that integer value in second to a datetime date:\n",
    "time_index = np.zeros(len(times1),dtype='datetime64[s]')\n",
    "for i in range(len(times1)):\n",
    "    time_index[i] = supporting_routines_m.timestamp2datetime(times1[i])\n",
    "\n",
    "    \n",
    "# Creating lat, long vectors for auxiliary plots e.g. cartopy\n",
    "\n",
    "lat = prior_all['lat'].values[lat_long_mask]\n",
    "long = prior_all['long'].values[lat_long_mask]\n",
    "\n",
    "# Creating a \"local\" prior: Subset of \"prior_all\" \n",
    "# that contains only the selected lat,long area.\n",
    "\n",
    "prior_local = supporting_routines_m.maskPrior(prior_all, time_index, lat_long_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the humidity profiles to a logarithmic scale\n",
    "# in order to improve their normality (see probability plots)\n",
    "\n",
    "# IMPORTANT NOTE:\n",
    "# RTTOV ACCEPTS ONLY kg / kg (LINEAR SCALE)\n",
    "# THERE IS A LOG2LIN CONVERSION IN THE DEFINITION\n",
    "# OF THE FORWARD OPERATOR; BUT INSIDE THE OPTIMAL\n",
    "# ESTIMATION, THE HUMIDITY IS IN LOG SCALE\n",
    "\n",
    "prior_local['Humidity'] = np.log10(prior_local['Humidity'])\n",
    "#prior_local['U10'] = np.abs(prior_local['U10'])\n",
    "#prior_local['V10'] = np.abs(prior_local['V10'])\n",
    "#prior_local['Humidity'] = prior_local['Humidity'] / 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create a simplistic K-Fold cross-validation scheme:\n",
    "# https://en.wikipedia.org/wiki/Cross-validation_(statistics)\n",
    "\n",
    "# all time indices in prior_local [0,1,...16000,..] :\n",
    "indexTotal = np.arange(len(prior_local.time)) \n",
    "\n",
    "# Create copy of the indices array\n",
    "kk = np.copy(indexTotal)\n",
    "\n",
    "# Shuffle the indices array randomly\n",
    "np.random.shuffle(kk)\n",
    "\n",
    "# Split the array in K folds (for K-fold cross validation)\n",
    "K = 10\n",
    "hh = np.array_split(kk,K)\n",
    "\n",
    "rmse = 0.0\n",
    "mae = 0.0 #np.empty(0)\n",
    "r2 = 0.0 #np.empty(0)\n",
    "count = np.empty(0,dtype=int)\n",
    "wind_opt = np.empty(0)\n",
    "wind_true = np.empty(0)\n",
    "wind_opt_err = np.empty(0)\n",
    "\n",
    "KK = 0\n",
    "\n",
    "for indexTest in hh: \n",
    "    \n",
    "    KK += 1\n",
    "# How many \"situations\" do we want to test \n",
    "#(these will be split apart from the a-priori dataset).\n",
    "# Situation means a (Lat, Long, time) combination:\n",
    "# i.e. 1 Situation is one datapoint from the prior_local dataset\n",
    "    nTestSamples = len(indexTest) \n",
    "\n",
    "# The test indices are deleted from the a-priori (i.e. training) set\n",
    "    indexTrain = np.delete(indexTotal,indexTest)\n",
    "\n",
    "# Split available diverse datasets into:\n",
    "# - 5 profiles to generate synthetic data (profiles)\n",
    "# - Rest of the profiles to generate the prior \n",
    "# The 5 profiles for synthetic data are EXCLUDED from\n",
    "# the rest of the datasets (e.g. from the prior)\n",
    "\n",
    "    profiles = prior_local.isel(time=indexTest)\n",
    "    prior_local_1 = prior_local.isel(time=indexTrain)\n",
    "    \n",
    "    # Number of levels of profile-like variables: (137 in this example)\n",
    "    nLev = len(prior_local_1.height)\n",
    "    \n",
    "    # Splitting the priors per season:\n",
    "    priors, pressure, seasons, months, h_season = \\\n",
    "        supporting_routines_m.priors2seasons(prior_local_1) \n",
    "    \n",
    "\n",
    "    flavor = 2 # check \"priors2Pandas\"\n",
    "    \n",
    "    # In short, flavor defines which variables from the dataset (temp, hum, wind speed, etc.)\n",
    "    # are going to be retrieved (i.e. x, state vector) and which variables\n",
    "    # are part of the parameters for the forward model (i.e. b, parameters vector)\n",
    "    # For this simple example I defined 4 flavors (see other flavors definition in\n",
    "    # \"support/priors2Pandas\"). Flavor 2 means: retrieve wind speed components and skin temperature\n",
    "    # Here in this excercise we assume that surface temperature and skin temperature are the same thing\n",
    "    \n",
    "    prior_xa, prior_b = \\\n",
    "        supporting_routines_m.priors2Pandas(\n",
    "                    priors, flavor = flavor, h_season = h_season) \n",
    "\n",
    "    # For state vector variables:\n",
    "    # Compute the means and covariance matrices \n",
    "    x_cov, x_mean = supporting_routines_m.meanCov(prior_xa, seasons)\n",
    "    \n",
    "    # Assert invertibility of the convariance matrices:\n",
    "    for season in x_cov.season:\n",
    "        assert np.linalg.matrix_rank(\n",
    "            x_cov.sel(season=season).to_pandas()) ==  x_cov.shape[-1]\n",
    "        \n",
    "    # Definition of the state variables (e.g. names of the variables)\n",
    "    x_vars = x_mean.state.values\n",
    " \n",
    "    # For parameters:\n",
    "    # Compute the means and covariance matrices \n",
    "    b_cov, b_mean = supporting_routines_m.meanCov(prior_b, seasons)\n",
    "    \n",
    "    # Assert invertibility of the convariance matrices:\n",
    "    for season in x_cov.season:\n",
    "        assert np.linalg.matrix_rank(\n",
    "            b_cov.sel(season=season).to_pandas()) ==  b_cov.shape[-1]   \n",
    "    \n",
    "    # Definition of the parameters (e.g. names of the variables)\n",
    "    b_vars = b_mean.state.values\n",
    "\n",
    "        \n",
    "    # Create x_truths: Pandas version of the profiles array \n",
    "    x_truths = supporting_routines_m.createTrueState(profiles, flavor=flavor)\n",
    "    \n",
    "    \n",
    "    w_op2 = np.empty(0)\n",
    "    w_op_err2 = np.empty(0)\n",
    "    w_truth2 = np.empty(0)\n",
    "    u_op2 = np.empty(0)\n",
    "    u_op_err2 = np.empty(0)\n",
    "    u_truth2 = np.empty(0)\n",
    "    v_op2 = np.empty(0)\n",
    "    v_op_err2 = np.empty(0)\n",
    "    v_truth2 = np.empty(0)    \n",
    "    lat_local = np.empty(0)\n",
    "    long_local = np.empty(0)\n",
    "    lat_skip = np.empty(0)\n",
    "    long_skip = np.empty(0)\n",
    "    seasonal = np.empty(0,dtype=object)\n",
    "        \n",
    "    count_breaks = 0\n",
    "    count_nc = 0\n",
    "    \n",
    "    startTimeFold = time.time()\n",
    "    \n",
    "    for ind in np.arange(len(indexTest)):\n",
    "\n",
    "        prof = profiles.time.values[ind] \n",
    "        seasonIndex = int(np.where(\n",
    "                            np.isin(\n",
    "                                months,profiles['time.month'].values[ind]))[0])\n",
    "        season_prof = seasons[seasonIndex]\n",
    "\n",
    "        # Profile used for generating synthetic observation:\n",
    "\n",
    "        x_truth = x_truths.iloc[ind]\n",
    "\n",
    "        Pressure = pressure.loc[season_prof,:].values[:] \n",
    "\n",
    "        # Other parameters needed for the radiative transfer model (RTTOV)\n",
    "        lat1 = np.float64(profiles.lat.values[ind])\n",
    "        long1 = np.float64(profiles.long.values[ind])\n",
    "        datetime_obs = prof\n",
    "        zenithAngle = 53.0 # Harcoded incidence angle for SSMIS\n",
    "        salinity = 35      # Harcoded salinity of sea water\n",
    "\n",
    "        # Create instance of Profiles class; \n",
    "        # it's a container of the input atmospheric state that RTTOV will simulate\n",
    "\n",
    "        myProfiles = pyrttov.Profiles(nprofiles, nlevels)\n",
    "\n",
    "        # Initialize multiple profiles for using a single call to RTTOV\n",
    "        # This is to be passed to the Jacobian function inside pyOpEst:\n",
    "        # The Jacobian is needed per parameter (len(x_truth.index))\n",
    "        nprofiles_test = len(x_truth.index) # total number of parameters (x and b)\n",
    "        myProfilesM = pyrttov.Profiles(nprofiles_test, nlevels) #  #Testing!\n",
    "\n",
    "        # forward_b_init fills \"myProfiles\" with the \"fixed\" parameters for the RTTOV simulation.\n",
    "        # The forward model F(x,b), RTTOV in our case, has two \"parameters\": x and b\n",
    "        # x is the state vector that is being retrieved (as such it is allowed to change during the retrieval)\n",
    "        # b contains all other parameters that are fixed during the retrieval (everything else that is not being retrieved)\n",
    "\n",
    "        forward_b_init(Pressure, salinity, \n",
    "              lat1, long1, datetime_obs, zenithAngle, myProfiles)\n",
    "\n",
    "    \n",
    "        press2 = np.zeros((nlevels,nprofiles_test))\n",
    "        x_truth_aux_data = np.zeros((nprofiles_test,nprofiles_test), dtype=np.float64) \n",
    "        columns_xtruth = []\n",
    "        for jj in np.arange(nprofiles_test):\n",
    "            press2[:,jj] = pressure.loc[season_prof,:].to_numpy()\n",
    "            x_truth_aux_data[:,jj] = x_truth.to_numpy() \n",
    "            columns_xtruth.append('profile_'+str(jj))\n",
    "\n",
    "        #x_truth_aux = pd.DataFrame(x_truth_aux_data,\n",
    "        #    columns=columns_xtruth, index=x_truth.index, dtype=np.float64)\n",
    "        \n",
    "# Initialize profile datastructure for use in Jacobian computation:        \n",
    "        forward_b_init(press2, salinity, \n",
    "              lat1, long1, datetime_obs, zenithAngle, myProfilesM)    \n",
    "        \n",
    "# Define a-priori information: mean and covariance matrix\n",
    "# for a given season (DJF, MAM, JJA, SON)\n",
    "\n",
    "        x_a = x_mean.sel(season=season_prof).to_pandas()[x_vars]\n",
    "        S_a = x_cov.sel(season=season_prof).to_pandas().loc[x_vars, x_vars]\n",
    "        \n",
    "        # Vector of parameters and its covariance:\n",
    "        b_p = b_mean.sel(season=season_prof).to_pandas()[b_vars]\n",
    "        S_b = b_cov.sel(season=season_prof).to_pandas().loc[b_vars, b_vars]\n",
    "            \n",
    "# Define dictionary of parameters for the forward model:\n",
    "\n",
    "        forwardKwArgs = {\"myProfiles_a\" : myProfiles, \n",
    "                         \"ssmiRttov_a\" : ssmiRttov}\n",
    "                \n",
    "# Dictionary for multiple profiles   \n",
    " \n",
    "        forwardKwArgsM = {\"myProfiles_a\" : myProfilesM, \n",
    "                         \"ssmiRttov_a\" : ssmiRttovM}    \n",
    "       \n",
    "        \n",
    "# Call the forward model (i.e. creating synthetic obs.)\n",
    "\n",
    "        y_obs = forwardRT(x_truth, **forwardKwArgs)\n",
    "        y_obs = pd.Series(y_obs, index=y_vars)\n",
    "        assert np.all(np.isfinite(y_obs))\n",
    "        \n",
    "        #jac = KRT(x_truth,y_vars, **forwardKwArgs)  # only for testing runK model from RTTOV, experimental!\n",
    "\n",
    "        \n",
    "        #print('y_obs done') \n",
    "# Create optimalEstimation instance:\n",
    "\n",
    "        oe_ref = pyOE.optimalEstimation( # oe_1 if windDisambiguation used\n",
    "            x_vars, # state variable names\n",
    "            x_a,  # a priori\n",
    "            S_a, # a priori uncertainty\n",
    "            y_vars,  # measurement variable names\n",
    "            y_obs, # observations\n",
    "            S_y, # observation uncertainty\n",
    "            forwardRT, # forward Operator\n",
    "            #rttovK,  # RTTOV's K model operator\n",
    "            forwardKwArgs=forwardKwArgs, # additonal function arguments\n",
    "            forwardKwArgsM=forwardKwArgsM, # additonal function arguments for jacobian tests\n",
    "            x_truth=x_truth, # true profile\n",
    "            b_vars=b_vars,   # Parameter vector variable names\n",
    "            b_p=b_p,        # Parameter vector \n",
    "            S_b=S_b,        # Parameters error covariance matrix \n",
    "            disturbance=0.01\n",
    "        )\n",
    "\n",
    "        oe_ref.doRetrieval()\n",
    "        \n",
    "        #time.sleep(3600)\n",
    "        \n",
    "        if not oe_ref.converged :  # oe_1 if windDisambiguation used\n",
    "            count_nc += 1\n",
    "            print('NO CONVERGENCE points:')\n",
    "            print(count_nc)\n",
    "            lat_skip = np.append(lat_skip,lat1)\n",
    "            long_skip = np.append(long_skip,long1)\n",
    "            continue\n",
    "        \n",
    "    # U & V:\n",
    "        _,_,u_op1, v_op1,_,_,_ = supporting_routines_m.splitX_all(oe_ref.x_op)\n",
    "        _,_,u_op_err1, v_op_err1,_,_,_ = supporting_routines_m.splitX_all(oe_ref.x_op_err)\n",
    "\n",
    "        _,_,u_truth1, v_truth1,_,_,_ = supporting_routines_m.splitX_all(oe_ref.x_truth)\n",
    "        u_op2 = np.append(u_op2,u_op1)\n",
    "        u_op_err2 = np.append(u_op_err2,u_op_err1)\n",
    "        u_truth2 = np.append(u_truth2,u_truth1)\n",
    "        v_op2 = np.append(v_op2,v_op1)\n",
    "        v_op_err2 = np.append(v_op_err2,v_op_err1)\n",
    "        v_truth2 = np.append(v_truth2,v_truth1)          \n",
    "    # Compute magnitude using coordinates U and V\n",
    "        w_op1, w_op_err1 = supporting_routines_m.UV2Wvar(oe_ref.S_op.loc['00010_nu','00010_nu'],\n",
    "                                                  oe_ref.S_op.loc['00010_nv','00010_nv'],\n",
    "                                                  oe_ref.S_op.loc['00010_nu','00010_nv'],\n",
    "                                                  u_op1,v_op1)        \n",
    "        w_truth1 = np.sqrt( u_truth1**2 + v_truth1**2 )   \n",
    "        \n",
    "        \n",
    "        # We keep track of the results in this fold for plotting later:\n",
    "\n",
    "        w_op2 = np.append(w_op2,w_op1)\n",
    "        w_op_err2 = np.append(w_op_err2,w_op_err1)\n",
    "        w_truth2 = np.append(w_truth2,w_truth1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        seasonal = np.append(seasonal,season_prof)\n",
    "        \n",
    "        lat_local = np.append(lat_local,lat1)\n",
    "        long_local = np.append(long_local,long1)\n",
    "        \n",
    "        print('index:')\n",
    "        print(ind)\n",
    "        \n",
    "    print(\"%.2f s , TimeFold\" % (time.time()-startTimeFold))    \n",
    "    \n",
    "    plotInMap(lat_local, long_local, lat, long, KK, lat_skip, long_skip)\n",
    "    perSeasonPlots(w_truth2, w_op2, seasonal, KK, windType = 'W10m')\n",
    "    perSeasonPlots(u_truth2, u_op2, seasonal, KK, windType = 'U10m')\n",
    "    perSeasonPlots(v_truth2, v_op2, seasonal, KK, windType = 'V10m')\n",
    "    \n",
    "    rmse_local, mae_local, r2_local = regressPlots(w_truth2, w_op2, KK, windType = 'W10m')   \n",
    "    _, _, _ = regressPlots(u_truth2, u_op2, KK, windType = 'U10m')\n",
    "    _, _, _ = regressPlots(v_truth2, v_op2, KK, windType = 'V10m')\n",
    "    \n",
    "    rmse += rmse_local\n",
    "    mae += mae_local\n",
    "    r2 += r2_local\n",
    "    \n",
    "\n",
    "rmse = rmse / KK\n",
    "mae = mae / KK\n",
    "r2 = r2 / KK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.linalg.matrix_rank(b_cov.sel(season=season).to_pandas())\n",
    "#b_cov.shape[-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardRT(X, myProfiles_a, ssmiRttov_a):\n",
    "    \n",
    "    # TODO: Add assertions, tests *** mario\n",
    "\n",
    "    temperature, humidity, u10m, v10m, bp2m, bt2m, btsk \\\n",
    "    = supporting_routines_m.splitX_all(X) \n",
    "    \n",
    "    \n",
    "    # humdity is in log10 scale, convert to linear in kg/kg\n",
    "    humidity = (10**humidity) / 1000.\n",
    "\n",
    "    myProfiles_a.T = reshape4profiles(temperature.to_numpy(dtype=np.float64))  \n",
    "    myProfiles_a.Q = reshape4profiles(humidity.to_numpy(dtype=np.float64))  \n",
    "\n",
    "    myProfiles_a.S2m[:,0] = reshape4profiles(\n",
    "        bp2m.to_numpy(dtype=np.float64)).flatten() # surface pressure\n",
    "    myProfiles_a.S2m[:,1] = reshape4profiles(\n",
    "        bt2m.to_numpy(dtype=np.float64)).flatten()  # 2m temperature\n",
    "    myProfiles_a.Skin[:,0] = reshape4profiles(\n",
    "        btsk.to_numpy(dtype=np.float64)).flatten() \n",
    "    \n",
    "    # if wind in components:\n",
    "    myProfiles_a.S2m[:,3] = reshape4profiles(\n",
    "        u10m.to_numpy(dtype=np.float64)).flatten()  #  10m windspeed, u component\n",
    "    myProfiles_a.S2m[:,4] = reshape4profiles(\n",
    "        v10m.to_numpy(dtype=np.float64)).flatten()  #  10m windspeed, v component  \n",
    "    \n",
    "   \n",
    "    ssmiRttov_a.Profiles = myProfiles_a\n",
    "    \n",
    "    #ssmiRttov_a.SurfEmisRefl[:,:,:] = -1. # need to \"reset\" to -1 every time RTTOV is called; \n",
    "    # -1 indicates to RTTOV to use internal values for surface emissivity.\n",
    "\n",
    "    try:\n",
    "        ssmiRttov_a.runDirect()\n",
    "    except pyrttov.RttovError as e:\n",
    "        sys.stderr.write(\"Error running RTTOV direct model: {!s}\".format(e))\n",
    "        sys.exit(1)    \n",
    "    \n",
    "    if(ssmiRttov_a.BtRefl[:, :].shape[0]==1):\n",
    "        TB = ssmiRttov_a.BtRefl[0, :].T\n",
    "    else:\n",
    "        TB = ssmiRttov_a.BtRefl[:, :].T\n",
    "    \n",
    "    return TB\n",
    "\n",
    "def rttovK(X, xb_err, y_var, myProfiles_a, ssmiRttov_a):\n",
    "    \n",
    "    # TODO: Add assertions, tests *** mario\n",
    "\n",
    "    temperature, humidity, u10m, v10m, bp2m, bt2m, btsk \\\n",
    "    = supporting_routines_m.splitX_all(X) \n",
    "    \n",
    "    qlog = humidity.copy()\n",
    "    # humdity is in log10 scale, convert to linear in kg/kg\n",
    "    humidity = (10**humidity) / 1000.\n",
    "\n",
    "    myProfiles_a.T = reshape4profiles(temperature.to_numpy(dtype=np.float64))  \n",
    "    myProfiles_a.Q = reshape4profiles(humidity.to_numpy(dtype=np.float64))  \n",
    "\n",
    "    myProfiles_a.S2m[:,0] = reshape4profiles(\n",
    "        bp2m.to_numpy(dtype=np.float64)).flatten() # surface pressure\n",
    "    myProfiles_a.S2m[:,1] = reshape4profiles(\n",
    "        bt2m.to_numpy(dtype=np.float64)).flatten()  # 2m temperature\n",
    "    myProfiles_a.Skin[:,0] = reshape4profiles(\n",
    "        btsk.to_numpy(dtype=np.float64)).flatten() \n",
    "    \n",
    "    # if wind in components:\n",
    "    myProfiles_a.S2m[:,3] = reshape4profiles(\n",
    "        u10m.to_numpy(dtype=np.float64)).flatten()  #  10m windspeed, u component\n",
    "    myProfiles_a.S2m[:,4] = reshape4profiles(\n",
    "        v10m.to_numpy(dtype=np.float64)).flatten()  #  10m windspeed, v component  \n",
    "    \n",
    "   \n",
    "    ssmiRttov_a.Profiles = myProfiles_a\n",
    "    \n",
    "    #ssmiRttov_a.SurfEmisRefl[:,:,:] = -1. # need to \"reset\" to -1 every time RTTOV is called; \n",
    "    # -1 indicates to RTTOV to use internal values for surface emissivity.\n",
    "    \n",
    "    try:\n",
    "        ssmiRttov_a.runK()\n",
    "    except pyrttov.RttovError as e:\n",
    "        sys.stderr.write(\"Error running RTTOV direct model: {!s}\".format(e))\n",
    "        sys.exit(1)\n",
    "    \n",
    "\n",
    "    # Create Jacobian Dataframe skeleton:\n",
    "    jacx = pd.DataFrame(index=y_var, columns=X.index)  \n",
    "    \n",
    "    # Fill-in Jacobian Dataframe\n",
    "    jacx = supporting_routines_m.mergeX_all(jacx.T, X, \n",
    "                                            ssmiRttov_a, LogHum=True)\n",
    " \n",
    "    # get Jacobian respect to logarithmic q:\n",
    "    #q_index = [i for i in X.index if i.endswith('q')]\n",
    "    #print(jacx.loc[q_index])\n",
    "    #jacx.loc[q_index] = jacx.loc[q_index]*\\\n",
    "    #                    qlog.to_numpy(dtype=np.float64\n",
    "    #                                 ).reshape(len(qlog.index),1)*0.1\n",
    "    #print(jacx.loc[q_index])\n",
    "    #print(qlog)\n",
    "    #print(humidity)\n",
    "    \n",
    "    return jacx.T.to_numpy(dtype=np.float64) \n",
    "\n",
    "\n",
    "def reshape4profiles(profiles):\n",
    "    # \"profiles\" is a numpy array\n",
    "    # \"profiles\" can contain 1 or more profiles\n",
    "    # \"profiles\" has dimensions (nlevels, nprofiles)\n",
    "    # \"outProfiles\" has dimensions (nprofiles,nlevels) (as needed in RTTOV)\n",
    "    \n",
    "    if (len(profiles.shape)==1):\n",
    "        outProfiles = profiles.reshape(1,profiles.shape[0]).copy()\n",
    "    else:\n",
    "        outProfiles = profiles.T.copy() #profiles.reshape(profiles.shape[1]\n",
    "            #                          ,profiles.shape[0]) \n",
    "    return outProfiles    \n",
    "\n",
    "\n",
    "def forward_b_init(pressure, salinity, lat, long, datetime_obs64, \n",
    "                   zenithAngle, myProfiles):\n",
    "    \n",
    "    if (len(pressure.shape)==1):\n",
    "        nprofiles = 1\n",
    "    else:\n",
    "        nprofiles =  pressure.shape[1]\n",
    "    \n",
    "    # The rest of the code uses datetime64 format (numpy), but I have to pass the obs date as integers to RTTOV\n",
    "    datetime_obs = supporting_routines_m.datetime64_to_datetime(datetime_obs64)\n",
    "    \n",
    "    s2m = np.zeros((nprofiles,6), dtype=np.float64) # s2m has 6 elements (docs RTTOV)\n",
    "    \n",
    "    angles = np.zeros((nprofiles,4), dtype=np.float64) # angles has 4 elements (docs RTTOV)\n",
    "    angles[:,0] = zenithAngle\n",
    "    \n",
    "    \n",
    "    # for RTTOV 13 skin is 9 elements long:\n",
    "    skin = np.zeros((nprofiles,9), dtype=np.float64) # skin has 9 elements (docs RTTOV)\n",
    "    skin[:,1] = salinity\n",
    "        \n",
    "    surftype = np.zeros((nprofiles,2), dtype=np.int32) # surftype has 2 elements (docs RTTOV)\n",
    "    surftype[:,:] = 1 # [sea, ocean] Harcoded for now, TODO *** mario\n",
    "    \n",
    "    \n",
    "    surfgeom = np.zeros((nprofiles,3), dtype=np.float64) # surfgeom has 3 elements (docs RTTOV)\n",
    "    surfgeom[:,0] = lat\n",
    "    surfgeom[:,1] = long\n",
    "    # surfgeom[:,2]=0 # elevation harcoded to 0 for now, TODO *** mario\n",
    "    \n",
    "    date_times = np.zeros((nprofiles,6), dtype=np.int32) # date_times has 6 elements (docs RTTOV)\n",
    "    date_times[:,0] = datetime_obs.year\n",
    "    date_times[:,1] = datetime_obs.month\n",
    "    date_times[:,2] = datetime_obs.day\n",
    "    date_times[:,3] = datetime_obs.hour\n",
    "    date_times[:,4] = datetime_obs.minute\n",
    "    date_times[:,5] = datetime_obs.second\n",
    "    \n",
    "    \n",
    "    myProfiles.GasUnits = 1  # kg/kg (see RTTOV doc. for other options) # Harcoded for now, TODO *** mario\n",
    "    myProfiles.P = reshape4profiles(pressure) \n",
    "    myProfiles.S2m = s2m\n",
    "    myProfiles.Angles = angles\n",
    "    myProfiles.Skin = skin\n",
    "    myProfiles.SurfType = surftype\n",
    "    myProfiles.SurfGeom = surfgeom\n",
    "    myProfiles.DateTimes = date_times\n",
    "    \n",
    "    #return myProfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotInMap(lat2, long2, lat, long, indice, lat_s = None, long_s = None):\n",
    "    \n",
    "    #lat2 = profiles.lat.values\n",
    "    #long2 = profiles.long.values\n",
    "\n",
    "    plt.figure(figsize=(13,6.2))\n",
    "    \n",
    "    ax = plt.subplot(111, projection=ccrs.PlateCarree())\n",
    "\n",
    "    ax.scatter(long,\\\n",
    "                   lat,marker='.',color='red')\n",
    "    ax.scatter(long2,\\\n",
    "                   lat2,marker='o',color='blue')\n",
    "    if (lat_s is not None)and(long_s is not None):\n",
    "        ax.scatter(long_s,\\\n",
    "                   lat_s,marker='o',color='yellow')\n",
    "                \n",
    "    ax.coastlines();\n",
    "\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax.set_xlabel('Longitude [deg]')\n",
    "    ax.set_ylabel('Latitude [deg]')\n",
    "\n",
    "    ax.stock_img();\n",
    "\n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(), linewidth=2, \n",
    "                      color='black', alpha=0.5, linestyle='--', draw_labels=True)\n",
    "    gl.xlabels_top = False\n",
    "    gl.ylabels_left = False\n",
    "    gl.ylabels_right=True\n",
    "    gl.xlines = True\n",
    "    gl.xlocator = mticker.FixedLocator([-180, -120, -60, 0, 60, 120, 180])\n",
    "    gl.ylocator = mticker.FixedLocator([-60, -30, 0, 30, 60])\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "\n",
    "    plt.savefig('Loc_Fold_'+str(indice)+'.png', dpi=300)\n",
    "\n",
    "def perSeasonPlots(truth,optimized,seasonal, indice, windType = 'W10m'):\n",
    "    \n",
    "    colors = {'DJF':'blue', 'MAM':'green', 'JJA':'orange', 'SON':'purple'}\n",
    "    \n",
    "    df = pd.DataFrame(dict(Truth=truth, Optimized=optimized, Season = seasonal))\n",
    "    \n",
    "    seasonGroup = df.groupby('Season')\n",
    "\n",
    "    for name, group in seasonGroup:\n",
    "        #print name\n",
    "        #print group \n",
    "        \n",
    "        w_truth = group['Truth'].values[:]\n",
    "        w_opt = group['Optimized'].values[:]\n",
    "\n",
    "        error_local = w_truth - w_opt\n",
    "        mean_error_local = np.mean( error_local )\n",
    "        median_error_local = np.median( error_local )\n",
    "        multiplicativeBias = np.mean(w_truth) / np.mean(w_opt)\n",
    "\n",
    "        rmse_local = np.sqrt(mean_squared_error(w_truth, w_opt)) \n",
    "        mae_local = median_absolute_error(w_truth, w_opt)\n",
    "        r2_local = r2_score(w_truth, w_opt)\n",
    "\n",
    "        \n",
    "        wt = np.reshape( w_truth, (len(w_truth),1) ) # for using with .fit below\n",
    "        \n",
    "        # Ordinary least squares:\n",
    "        regr = LinearRegression()\n",
    "    \n",
    "        # Robust fit with Ransac algo. (sklearn lib.)\n",
    "        ransac = RANSACRegressor()\n",
    "        \n",
    "        # HuberRegressor\n",
    "        #huber = HuberRegressor()\n",
    "\n",
    "        # Train the model using the training sets\n",
    "        \n",
    "            # OLS fit:\n",
    "        regr.fit(wt, w_opt)\n",
    "        # Ransac fit:\n",
    "        ransac.fit(wt, w_opt)\n",
    "        # Huber fit\n",
    "        #huber.fit(wt, w_opt)\n",
    "        \n",
    "        # mask inlier-outlier from Ransac:\n",
    "        inlier_mask = ransac.inlier_mask_\n",
    "        outlier_mask = np.logical_not(inlier_mask)\n",
    "        \n",
    "        # mask inlier-outlier from Huber:     \n",
    "        #outlier_mask = huber.outliers_\n",
    "        #inlier_mask = np.logical_not(outlier_mask)\n",
    "    \n",
    "        # Make predictions using the testing set\n",
    "        # OLS:\n",
    "        wind_pred = regr.predict(wt)  \n",
    "        # Ransac:\n",
    "        wind_ransac = ransac.predict(wt)\n",
    "        # Huber:\n",
    "        #wind_huber = huber.predict(wt)   \n",
    "    \n",
    "        fig, (ax1,ax2) = plt.subplots(ncols=2, sharey = True)\n",
    "        # Plot outputs\n",
    "        ax1.scatter(w_truth, w_opt,  c=group['Season'].map(colors), alpha= 0.5, label = 'Optimal vs True')\n",
    "        ax1.plot(w_truth, wind_pred, color='black', linewidth=1.5, label = 'Linear regression')\n",
    "        ax1.plot(w_truth, w_truth, color='gray', linewidth=1.5, label = 'Slope 1 line')\n",
    "\n",
    "        ax1.set_ylabel('NS Wind Speed [m/s], Retrieved')\n",
    "        ax1.set_xlabel('NS Wind Speed [m/s], True')\n",
    "        ax1.grid(True)\n",
    "        ax1.set_title('OLS '+windType)\n",
    "        ax1.text(\n",
    "            0.95,\n",
    "            0.05,\n",
    "            '%s\\nm = %.3g\\nb = %.3g%s\\nrmse = %.3g%s\\nmae = %.3g%s\\nr$^2$ = %.3g' % (\n",
    "                '$mx+b$',\n",
    "                np.float(regr.coef_),\n",
    "                np.float(regr.intercept_),'m/s',\n",
    "                rmse_local,'m/s',\n",
    "                mae_local,'m/s',\n",
    "                r2_local),\n",
    "            horizontalalignment='right',\n",
    "            verticalalignment='bottom',\n",
    "            transform=ax1.transAxes)\n",
    "        \n",
    "        # Plot Ransac\n",
    "        ax2.scatter(w_truth[inlier_mask], w_opt[inlier_mask],  \n",
    "                c=group['Season'][inlier_mask].map(colors), alpha = 0.5, label = 'Retrieved')\n",
    "        ax2.scatter(w_truth[outlier_mask], w_opt[outlier_mask],  \n",
    "                color='magenta', alpha = 0.4, label = 'Outlier')\n",
    "        ax2.plot(w_truth, wind_ransac, color='black', linewidth=1.5, label = 'Regression')\n",
    "        ax2.plot(w_truth, w_truth, color='gray', linewidth=1.5, label = 'm = 1')\n",
    "    \n",
    "        ax2.legend()\n",
    "        ax2.set_xlabel('NS Wind Speed [m/s], True')\n",
    "        ax2.grid(True)\n",
    "        ax2.set_title('Ransac '+windType)\n",
    "        ax2.text(\n",
    "            0.95,\n",
    "            0.05,\n",
    "            '%s\\nm = %.3g\\nb = %.3g%s\\nrmse = %.3g%s\\nmae = %.3g%s\\nr$^2$ = %.3g' % (\n",
    "                '$mx+b$',\n",
    "                np.float(ransac.estimator_.coef_),\n",
    "                np.float(ransac.estimator_.intercept_),'m/s',\n",
    "                np.sqrt(mean_squared_error(w_truth[inlier_mask], w_opt[inlier_mask])) ,'m/s',\n",
    "                median_absolute_error(w_truth[inlier_mask], w_opt[inlier_mask]),'m/s',\n",
    "                np.float(r2_score(w_truth[inlier_mask], w_opt[inlier_mask]))),\n",
    "            horizontalalignment='right',\n",
    "            verticalalignment='bottom',\n",
    "            transform=ax2.transAxes)\n",
    "\n",
    "        plt.legend(loc=(0.02,0.73), prop={'size': 9}) \n",
    "        plt.savefig('seas_wind'+name+windType+'_'+str(indice), dpi=300)  \n",
    "        \n",
    "        # Histogram\n",
    "        bins_all = 5\n",
    "\n",
    "        fig, ax = plt.subplots(1)\n",
    "        ax.hist(error_local, bins = bins_all, label=name)\n",
    "        ax.legend()\n",
    "        ax.text(0.95,0.75,\n",
    "                'Mean error = %.3g\\nMedian error = %.3g\\nBias (M) = %.3g' % ( \n",
    "                    mean_error_local, \n",
    "                    median_error_local,\n",
    "                    multiplicativeBias),\n",
    "                horizontalalignment='right',\n",
    "                verticalalignment='top',\n",
    "                transform=ax.transAxes)\n",
    "    \n",
    "        ax.grid(True)\n",
    "        plt.savefig('seas_err'+name+windType+'_'+str(indice), dpi=300)\n",
    "    \n",
    "def regressPlots(truth, optimized, indice, windType = 'Wind'):\n",
    "    \n",
    "        #error_local = truth - optimized\n",
    "        #mean_error_local = np.mean( error_local )\n",
    "        #median_error_local = np.median( error_local )\n",
    "    \n",
    "        rmse_local = np.sqrt(mean_squared_error(truth, optimized)) \n",
    "        mae_local = median_absolute_error(truth, optimized)\n",
    "        r2_local = r2_score(truth, optimized)\n",
    "\n",
    "    \n",
    "        # Ordinary least squares:\n",
    "        regr = LinearRegression()\n",
    "    \n",
    "        # Robust fit with Ransac algo. (sklearn lib.)\n",
    "        ransac = RANSACRegressor()\n",
    "    \n",
    "        # Train the model using the training sets\n",
    "        wt = np.reshape(truth,(len(truth),1)) # for using with .fit below\n",
    "    \n",
    "        # OLS fit:\n",
    "        regr.fit(wt, optimized)\n",
    "        # Ransac fit:\n",
    "        ransac.fit(wt, optimized)\n",
    "        # mask inlier-outlier from Ransac:\n",
    "        inlier_mask = ransac.inlier_mask_\n",
    "        outlier_mask = np.logical_not(inlier_mask)\n",
    "    \n",
    "        # Make predictions using the testing set\n",
    "        # OLS:\n",
    "        wind_pred = regr.predict(wt)  \n",
    "        # Ransac:\n",
    "        wind_ransac = ransac.predict(wt)\n",
    "    \n",
    "        fig, (ax1,ax2) = plt.subplots(ncols=2, sharey = True)\n",
    "        # Plot outputs\n",
    "        ax1.scatter(truth, optimized,  color='dodgerblue', alpha = 0.5, label = 'Optimal vs True')\n",
    "        ax1.plot(truth, wind_pred, color='black', linewidth=1.5, label = 'Linear regression')\n",
    "        ax1.plot(truth, truth, color='gray', linewidth=1.5, label = 'Slope 1 line')\n",
    "\n",
    "        ax1.set_ylabel('NS Wind Speed [m/s], Retrieved')\n",
    "        ax1.set_xlabel('NS Wind Speed [m/s], True')\n",
    "        ax1.grid(True)\n",
    "        ax1.set_title('OLS '+windType)\n",
    "        ax1.text(\n",
    "            0.95,\n",
    "            0.05,\n",
    "            '%s\\nm = %.3g\\nb = %.3g%s\\nrmse = %.3g%s\\nmae = %.3g%s\\nr$^2$ = %.3g' % (\n",
    "            '$mx+b$',\n",
    "            np.float(regr.coef_),\n",
    "            np.float(regr.intercept_),'m/s',\n",
    "            rmse_local,'m/s',\n",
    "            mae_local,'m/s',\n",
    "            r2_local),\n",
    "            horizontalalignment='right',\n",
    "            verticalalignment='bottom',\n",
    "            transform=ax1.transAxes)\n",
    "\n",
    "        # Plot outputs\n",
    "        ax2.scatter(truth[inlier_mask], optimized[inlier_mask],  \n",
    "                color='dodgerblue', alpha = 0.5, label = 'Retrieved')\n",
    "        ax2.scatter(truth[outlier_mask], optimized[outlier_mask],  \n",
    "                color='magenta', alpha = 0.5, label = 'Outlier')\n",
    "        ax2.plot(truth, wind_ransac, color='black', linewidth=1.5, label = 'Regression')\n",
    "        ax2.plot(truth, truth, color='gray', linewidth=1.5, label = 'm = 1')\n",
    "    \n",
    "        ax2.legend()\n",
    "        ax2.set_xlabel('NS Wind Speed [m/s], True')\n",
    "        ax2.grid(True)\n",
    "        ax2.set_title('Ransac '+windType)\n",
    "        ax2.text(\n",
    "            0.95,\n",
    "            0.05,\n",
    "            '%s\\nm = %.3g\\nb = %.3g%s\\nrmse = %.3g%s\\nmae = %.3g%s\\nr$^2$ = %.3g' % (\n",
    "            '$mx+b$',\n",
    "            np.float(ransac.estimator_.coef_),\n",
    "            np.float(ransac.estimator_.intercept_),'m/s',\n",
    "            np.sqrt(mean_squared_error(truth[inlier_mask], optimized[inlier_mask])) ,'m/s',\n",
    "            median_absolute_error(truth[inlier_mask], optimized[inlier_mask]),'m/s',\n",
    "            np.float(r2_score(truth[inlier_mask], optimized[inlier_mask]))),\n",
    "            horizontalalignment='right',\n",
    "            verticalalignment='bottom',\n",
    "            transform=ax2.transAxes)\n",
    "\n",
    "        plt.legend(loc=(0.02,0.73), prop={'size': 9}) \n",
    "        plt.savefig('windR_'+windType+str(indice), dpi=300)\n",
    "        \n",
    "        return rmse_local, mae_local, r2_local\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
